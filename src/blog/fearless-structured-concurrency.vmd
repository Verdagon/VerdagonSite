---
title: Combining Fearless Concurrency with Structured Concurrency
author: Evan Ovadia
date: Jan 8, 2022
realm: blog
path: blog/fearless-structured-concurrency
layout: annotated
namespace: c-blog m-annotated
---

With fearless structured concurrency, we can add multi-threading to existing code with a single keyword, with no risk of data races!


Summary:

 * "Structured" concurrency makes multi-threading much *easier*.
    * Threads can access data from the containing scope!
 * "Fearless" concurrency *prevents data races* between threads.
 * *Structured fearless concurrency combines the best of both worlds.*
 * Vale's `parallel` keyword makes it happen!


# We Want Structured Concurrency!


Structured concurrency is a lot of fun.


With structured concurrency, you can launch multiple threads at once, to run your calculations in parallel, for a big speedup. And often, it can be done with a tiny adjustment.


Imagine we had this simple program that calculated x^3 for some values of x:

```c
#include <math.h>
#include <stdio.h>

void main() {
  int exponent = 3;
  int results[5];

  // Calculate some exponents
  for (int i = 0; i < 5; i++) {
   results[i] = pow(i, exponent);
  }

  // Print out the results
  for (int i = 0; i < 5; i++) {
   printf("%d to the %d'th power is %d!\n", i, exponent, results[i]);
  }
}
```stdout
0^3 is 0!
1^3 is 1!
2^3 is 8!
3^3 is 27!
4^3 is 64!
```



If `pow` was much more expensive, we might want to run those calculations in parallel.

It's very tedious to run it in C. We'd have to wrap our `results[i] = pow(i, exponent);` line in an entire new function, and use `pthread_create`, like so:


```c
#include <math.h>
#include <stdio.h>
#include <pthread.h>

typedef struct {
  int exponent;
  int i;
  int* results;
} MyThreadArgs;

void *my_thread_main(void* args_raw) {
  MyThreadArgs* args = (MyThreadArgs*)args_raw;
  int exponent = args->exponent;
  int i = args->i;
  int* results = args->results;

  results[i] = pow(i, exponent); // some expensive calculation

  free(args_raw);
  return NULL;
}

int main() {
  int exponent = 3;

  int results[5];

  // Don't run each iteration one after the other...
  // run them in parallel, rather than serially.
  pthread_t threads[5];
  for (int i = 0; i < 5; i++) {
    MyThreadArgs* args = (MyThreadArgs*)malloc(sizeof(MyThreadArgs));
    args->exponent = exponent;
    args->i = i;
    args->results = results;
    pthread_create(&threads[i], NULL, my_thread_main, args);
  }
  // Join the threads
  for (int i = 0; i < 5; i++) {
    void* returnval = NULL;
    pthread_join(threads[i], &returnval);
  }

  for (int i = 0; i < 5; i++) {
    printf("%d to the %d'th power is %d!\n", i, exponent, results[i]);
  }
  return 0;
}
```


We needed a lot of code to just run `results[i] = pow(i, exponent);` in parallel!

With structured concurrency, we can do that with *just one line*. Let's add a `#pragma omp parallel for` to our original program: [# To run this, you might need to install OpenMP first. For my Mac, I needed to run `brew install libomp` and compile with `clang main.c -fopenmp -L/usr/local/Cellar/libomp/13.0.0/lib`.]


```c
#include <math.h>
#include <stdio.h>
#include <omp.h>

int main() {
  int exponent = 3;

  int results[5];
  
  // Launch some threads and run in parallel!
  #pragma omp parallel for
  for (int i = 0; i < 5; i++) {
    results[i] = pow(i, exponent); // some expensive calculation
  }

  for (int i = 0; i < 5; i++) {
    printf("%d to the %d'th power is %d!\n", i, exponent, results[i]);
  }
  return 0;
}
```



This is *structured concurrency*. It runs our iterations in parallel!


Structured concurrency is great for two reasons:

 * It's much easier! Only one line, rather than restructuring our entire program.
 * The threads can access data from the surrounding scope.
    * Notice how all of our threads are accessing `results` and `exponent`.


Nathaniel Smith makes a great case that we should use structured concurrency rather than directly using thread APIs such as `pthread_create`, `go`, `asyncio.create_task`, etc. [# See [Notes on structured concurrency, or: Go statement considered harmful](https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/).] Structured concurrency isn't a silver bullet, of course, but it's definitely a big step forward.


However, structured concurrency is still vulnerable to *data races*. Read on to find out what those are, and how another paradigm can fix them. Then, we'll combine the two!


<slice/>


# Data Races

Fearless concurrency prevents data races between threads. A *data race* is when: [# From [The Rustonomicon](https://doc.rust-lang.org/nomicon/races.html)]

 * two or more threads concurrently accessing a location of memory
 * one or more of them is a write
 * one or more of them is unsynchronized


Let's add a "progress" counter to our above snippet, and see a data race bug in action:

```c
#include <math.h>
#include <stdio.h>
#include <omp.h>

int main() {
  int exponent = 3;

  int results[5];

  int numIterationsCompleted = 0;
  
  // Launch some threads and run in parallel!
  #pragma omp parallel for
  for (int i = 0; i < 5; i++) {
    results[i] = pow(i, exponent); // some expensive calculation

    // Read, add, and store
    numIterationsCompleted = numIterationsCompleted + 1;
    printf("Completed %d iterations!\n", numIterationsCompleted);
  }

  for (int i = 0; i < 5; i++) {
    printf("%d to the %d'th power is %d!\n", i, exponent, results[i]);
  }
  return 0;
}
```stdout
Completed 1 iterations!
Completed 2 iterations!
Completed 3 iterations!
Completed 4 iterations!
Completed 4 iterations!
0 to the 3'th power is 0!
1 to the 3'th power is 1!
2 to the 3'th power is 8!
3 to the 3'th power is 27!
4 to the 3'th power is 64!
```

Look at that! There are two `Completed 4 iterations!` printed out. [# If this doesn't happen for you, try running it a few more times. It's rather fickle.] Why is that?


It's because the line `numIterationsCompleted = numIterationsCompleted + 1;` has three steps:

 * Load `numIterationsCompleted` into register A.
 * Add 1 to register A.
 * Store register A into `numIterationsCompleted`.


If two threads are running in parallel, we might see this happen:

 * 4th thread loads 3 from `numIterationsCompleted` into register A.
 * 5th thread loads 3 from `numIterationsCompleted` into register B.
 * 4th thread adds 1 to register A, it now contains 4.
 * 5th thread adds 1 to register B, it now contains 4.
 * 4th thread stores register A into `numIterationsCompleted`, it now contains 4.
 * 5th thread stores register B into `numIterationsCompleted`, it now contains 4.


The problem is that they didn't see each others add operations; they're both adding 1 to the old value 3, to get 4.

If instead the 4th thread's store happened before the 5th thread's load, we'd have gotten the correct answer 5.


This is a *data race* bugs. They are _very_ difficult to detect, because they depend on the scheduling of the threads.

Luckily, we've figured out how to avoid these problems, with some "concurrency ground rules":

 1. Multiple threads can read the same data, if nobody can modify it.
 1. If a thread can read data that another thread can modify, the data must be wrapped in a mutex. [# More on mutexes below.]
 1. If data is only visible to one thread, it can access that data freely.


We usually need proper fear, respect, and discipline to stick to these rules. But when a language enforces these rules, we have *fearless concurrency*.


<slice/>


# Fearless Concurrency

Plenty of languages (Clojure, Pony, Erlang, Rust, Dart, some others [# See Renato Athaydes' [Fearless concurrency: how Clojure, Rust, Pony, Erlang and Dart let you achieve that.](https://sites.google.com/a/athaydes.com/renato-athaydes/posts/fearlessconcurrencyhowclojurerustponyerlanganddartletyouachievethat)]) offer fearless concurrency, but we'll use Pony and Rust as examples.


## Message Passing with Pony

Pony doesn't let us access data from the outside scope, like in our above C examples. Instead, we "send" data between threads.


We can send data if *either* of these is true:

 * There are no other references to the data (it has the `iso` permission). [# A "permission" is something that travels along with a pointer at compile time, which affects how you may use that pointer. For example, Rust's `&` vs `&mut`, C++'s `*` vs `const *`, Vale's `&` vs `*`.]
 * It is deeply immutable (it has the `imm` permission).

To send an object to another thread, it must have the `imm` or `iso` permission.


It's a restrictive system, but data races are impossible. Huzzah!


<slice/>


## Why no Mutex?

Having a mutex is not enough to prevent data races.


For example, in Java, we would use a mutex like this:

```java
synchronized (myObj) {
  Counter counter = myObj.myCounter;
  myCounter.number = myCounter.number + 1;
}
```

This code looks good; the `synchronized` block will lock the mutex in `myObj` [# In Java, every object is (or contains) a mutex.] and then unlock it when the block ends.


However, the programmer can still mess this up: they can access `counter` after the block!

```java
Counter counter;
synchronized (myObj) {
  counter = myObj.myCounter;
  myCounter.number = myCounter.number + 1;
}
myCounter.number = myCounter.number + 7;
```


The problem is that references can *outlive* the mutex lock.


Luckily, there's a way to prevent that. Enter Rust!


<slice/>


## Mutexes with Rust

Just like how Pony tracks permissions, Rust tracks lifetimes, and can ensure that no reference escapes a mutex lock.

Here is the equivalent code in Rust: [# [Playground link](https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=8ce5115cc1d4117aeab61da2eef69f03)]

```rust
let m = Mutex::new(100i64);

let escaped_reference =
  {
    let counter = &mut *m.lock().unwrap();
    *counter = *counter + 1i64;
    counter
    // Error, because the counter pointer is escaping!
  };

println!("{:?}", *escaped_reference);
```

However, Rust is totally fine letting something else escape, since it didn't come from inside the mutex: [# [Playground link](https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=9151d40e3c0b4b12c72d67754c2a8845)]


```rust
let m = Mutex::new(100i64);

let escaped_value =
  {
    let counter = &mut *m.lock().unwrap();
    *counter = *counter + 1i64;
    let new_value = *counter + 100
    new_value
  };

println!("{:?}", escaped_value);
```


Rust uses the type system to track where a value came from. [# This part of the type system is called the "borrow checker". It's actually much more complicated and powerful than alluded to here.]


<slice/>


# How do we combine them?

We can make structured concurrency fearless by:

 1. Start with structured concurrency.
 1. We *can't* modify values created *outside* a parallel block.
 1. ...except for mutexes, we can always lock them.


Our C program _almost_ follows these rules, except it violates rule 2; we modified the `results` array inside the parallel block:


```c
int exponent = 3;

int results[5];

// Launch some threads and run in parallel!
#pragma omp parallel for
for (int i = 0; i < 5; i++) {
  results[i] = pow(i, exponent);
}
```



But Vale has a `foreach` loop that can accumulate each iteration's result, and produce an array: [# For those unfamiliar, Vale is a language that ... (put stuff here)]


```
exponent = 3;

results =
  parallel foreach 0..5 as i { «executor»
    = pow(i, exponent); «blockresult1»
  }
```



There! Now the loop doesn't modify anything created outside the block.


And just because we can, let's modify something created _inside_ the block:


```
fn main() export {
  exponent = 3;

  results =
    parallel foreach 0..5 as i {
      a = pow(i, exponent);
      set a = a + 4; // We can modify!
      = a; «blockresult2»
    }
}
```

You can see how the compiler can enforce that we only modify things that came from inside the block.


The type system also needs to track what we can modify and what we can't. For that, we use `'r`.


Note how in this snippet, `blur`'s first parameter's type is `'r Array<Array<int>>`. The `'r` enforces that the function won't modify the array from this function. [# This is similar to Rust's lifetimes, more on that below.]


```
fn main() export {
  // Makes a 2D array of ints
  input = Array(10, x => Array(10, y => x * 10 + y));

  results =
    parallel foreach 0..10 as x {
      = map 0..10 as y {
          = blur(input, x, y);
        }
    }
}

fn blur(input 'r &Array<Array<int>>, x int, y int) int {
  ... // Loop over the 3x3 ints around x,y in input and return the average
}
```



That `'r` means we're pointing into an *immutable region*. More on that below!


<slice>
#executor: The `parallel` block will by default spawn `num_cores * 2` threads, but it can also be specified via `parallel(num_threads)` or `parallel(an_executor)`.

#blockresult1: The `=` here means this line produces the block's result.

#blockresult2: The `=` here means this line produces the block's result.
</slice>


# Immutable References

As stated above, to enable fearless structured concurrency, we need to express that a reference points into an *immutable region*.


When an object is in an immutable region, we:

 * Can't modify it.
 * Can load a member (or element) from it.
    * The type system remembers that it's also in the immutable region.
 * Can pass it to a function, if the function knows it's from an immutable region.


We're using `'r` to specify that a reference is in an immutable region. For example, an `'r &Array<int>` is an non-owning reference to an array of integers inside an immutable region.



We can use these for our concurrency, with the following rule:

> When inside a `parallel` statement, everything outside is in an immutable region.



Elaborating on the `'r` a little more:

 * The `r` is arbitrary, we can name it anything we want.
 * The `'r` refers to a *scope*, or in other words, a *region*, similar to what Rust did above. [# This is similar to a lifetime in Rust, except that in Vale, mutability is per-region, not per-object: `'r` refers to an immutable region, `'r!` refers to a mutable region. There is no `&mut` in Vale. This adjustment makes the language easier to use, and enables fearless structured concurrency and other features.]
 * By default, any named region is *immutable*.
    * We can refer to a mutable region with `'r!` or just leave it unnamed.


This may sound familiar from C++ [# A `const *` is similar, but we might not get a `const *` when we load a member/element from it.] or Rust [# An immutable borrow (`&`) is similar, but we can still reach and modify objects inside `RefCell`s, so it doesn't quite work.], but they don't have anything quite like it.


<slice/>


# Mutexes

Multiple threads can modify some data if it's surrounded by a mutex.


If we have an immutable reference to a mutex, we can still lock it.


In this example, even though `num_iterations_completed_mutex` is outside the `parallel` block and therefore immutable, we can still lock it and modify the contained value.


```
exponent = 3;

num_iterations_completed_mutex = Mutex(0);

results =
  parallel foreach 0..5 as i {
    a = pow(i, exponent);

    // num_iterations_completed_mutex is from the surrounding
    // immutable region, but we can still lock it.
    lock num_iterations_completed_mutex as num_iterations_completed {
      set num_iterations_completed++;
    }

    = a;
  }
```



Any reference from inside the mutex can't escape the `lock` block, similar to how Rust detected it above.



# Conclusion

conclusion here


