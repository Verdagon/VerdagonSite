---
title: Higher RAII, and the Seven Arcane Uses of Linear Types
subtitle: Linear types + whitelisted destroyers = powers yet unimagined!
author: Evan Ovadia
date: May 14, 2024
realm: blog
path: blog/higher-raii-uses-linear-types
layout: annotated
namespace: c-blog m-annotated
---

! Also posted today: [Layer-wise inferencing + batching: Small VRAM doesn't limit LLM throughput anymore](/blog/llm-throughput-not-ram-limited), on how even a normal small computer can now run huge LLMs, much more quickly!


<ignore>
More uses:

 * Remember to shut off a motor
 * If you call update() on CoreData but it wont happen until you flush(), update() should return a RememberToFlush linear type that can only be consumed by flush() or forgetOnPurpose().
</ignore>


Can you spot the problem in each of these comments?

`// Remember to update the database row with the new status.`

`// Remember to remove(&cache, entityRef) before you destroy the entity!`

`// Remember to fulfill this promise with the result of the calculation.`


The problem, of course, is that they rely on our fallible human memory!


We'd love a way to guarantee that we remember to do something. Unfortunately, today's compilers and languages can't really solve this problem for us.


But hark! We can change that, with *Higher RAII*, a technique where we use linear types that can only be destroyed in certain places.


<div style="text-align: center"><img src="/images/asciigoblins.png" width="100%"/></div><div style="opacity: .8; text-align: center"><a href="https://youtu.be/UavYVf0UEoc?t=2246">Goblins like linear types and gardening.</a></div>


# What's a linear type?


If you look up linear types online, you'll find a lot of unhelpful definitions, like *a linear type is a type that can't be aliased, can't be cloned, and must be "used" exactly once.* [#defs]


That's somewhat unhelpful because, as Vale shows us, you can have a linear struct without any of the above restrictions.

 * You can read/modify it as much as you like.
 * You can copy it.
 * You can make aliases to it.


So for now, let's use a less correct but more helpful definition: *A linear struct must eventually be _explicitly_ destroyed.* [#acrobatics]


In other words, a linear struct can't just go out of scope. When the user lets a linear struct go out of scope, the compiler gives an error.


<<<<
Here we have a function that makes a linear struct `x`, makes a reference to it, and even reads its contents.

When `x` goes out of scope, we get a compile error.
////
```vale
linear struct MyStruct {
  m int;
}

func foo() {
  // x is type MyStruct.
  x = MyStruct(42);

  // Can make a reference.
  // r is type &MyStruct.
  r = &x;

  // Can read contents
  println(r.m);

  // ERROR: Undestructed linear `x`.
}
```
\\\\
Other languages might automatically clean it up, or call a destructor or `drop()` method, but here we've opted into the compiler error instead.


If we put in the line `destruct x;`, it would resolve the compiler error.
>>>>


This might seem like a weird restriction, but if we use it in a certain way, it can unlock some rather amazing capabilities:

 * Keep your caches consistent with your data
 * Prevent zombie temporary states
 * Prevent concurrency bugs and ensure messages are handled
 * Help with database consistency; prevent forgotten updates
 * Prevent certain kinds of memory leaks (even GC or Rust leaks!)
 * Prevent accidentally canceling an ongoing thread or connection
 * Prevent an accidental rollback of a perfectly good transaction
 * Guarantee a provided callback is actually called
 * Guarantee we eventually log something


So how can linear types help with all of that?

The answer is something I call *Higher RAII*, explained in the next section.


By the way, if linear types intrigue you, also check out this Developer Voices interview where I talked with Kris Jenkins about them:

<iframe name="ytvid1" style="width: 100%; max-width: 400px; display: block; margin: auto; aspect-ratio: 1.78;" src="https://www.youtube.com/embed/UavYVf0UEoc" title="Advanced Memory Management in Vale (with Evan Ovadia)" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

At <a href="https://www.youtube.com/embed/UavYVf0UEoc?start=958&end=1000" target="ytvid1">time 15:48</a> I talked a bit about how we can use linear types for Higher RAII, but the potential is so much more vast than I hinted in that interview. Read on to find out!


<slice>
#defs: Some definitions:

 * [Wikipedia](https://en.wikipedia.org/wiki/Substructural_type_system#Linear_type_systems): "Linear types correspond to linear logic and ensure that objects are used exactly once."
 * [martriay](https://medium.com/@martriay/rust-and-linear-types-a-short-guide-4845e9f1bb8f): "the constraint that each variable can be used exactly once" (though they explain the motivations really well)
 * [Cornell](https://www.cs.cornell.edu/courses/cs4110/2018fa/lectures/lecture29.pdf): In linear logic, you have to “use” every premise exactly once to construct the conclusion.]
 * [austral-lang.org](https://austral-lang.org/linear-types): a value of a linear type is a value that can only be used once.

#acrobatics: One can reconcile the two definitions with enough mental acrobatics. We could say that marking a Vale struct as `linear` means its _owning reference_ is linear.

 * We'd define "use" as "destroy"; now we can only use the linear type once.
 * Even though we can alias the struct (with a generational reference), we can't alias/clone the owning reference.
 * We can still read/modify the contents of the struct, but we can't directly read/modify the owning reference's underlying pointer.

</slice>

# Higher RAII = Linear types + whitelisted destroyers


Recall that *a linear struct must eventually be explicitly destroyed.*

Now, imagine a struct that must eventually be explicitly destroyed *by a specific function* (or functions).


We say that struct has *Higher RAII.*

I'll explain that term in a bit, [# RAII stands for "Resource Acquisition is Initialization", which is a secret key phrase that we C++ programmers whisper at the door to get into our secret covert gatherings. Careful: if they suspect you're an impostor, you'll be SFINAEd.] but first, let's see an example!


Imagine a `Transaction` struct that must eventually be `commit`ted or `rollback`ed.

In today's mainstream languages, [# C++ and Rust's RAII can get halfway, but they can only implicitly call a single zero-arg void-returning function, the destructor. Some pretty amazing things happen when you can choose among multiple destructors with parameters and returns.] the user might forget to call `commit` or `rollback`, causing the transaction to hang or make a guess. [# The most common strategy is to default to `rollback`, thankfully.] This cost me a few hours the other day in my [weird event collector](/blog/llm-throughput-not-ram-limited#background-the-flora-bama-mullet-toss), when I didn't `commit` one of my transactions.


To set up a `Transaction` struct with Higher RAII, we need to do three things.


<<<<
First, *make the struct linear*.

Here's some Vale as an example. [# The HEAD version does this, stable and older versions still use the `#!DeriveStructDrop` keyword.]
////
```vale
linear struct Transaction {
  ...
}
```
>>>>

This means the struct can never go out of scope; it can never be automatically destroyed. It must be _explicitly_ destroyed now, such as with Vale's `destruct` keyword, shown below.


<<<<
Second, *create the functions* that take the object and explicitly `destruct` it.


Here's our `commit` and `rollback` functions.
////
```vale
// (same file as struct Transaction)

func commit(txn Transaction, db &DB) {
  ... // code to commit the transaction

  destruct txn; // Explicitly destroy
}

func rollback(txn Transaction, db &DB) {

  ... // code to rollback the transaction

  destruct txn; // Explicitly destroy
}
```
\\\\
Note the `Transaction` parameter isn't `&Transaction`; the functions take the instance itself, not a reference.


They then `destruct` the `Transaction`.
>>>>


Third, make sure that *_only_ those functions can destroy the object*. 

In Vale, you don't actually have to do anything for this step: `destruct` can only be used from the file defining the struct.


*Success!* We're now guaranteed to `commit` or `destroy` every `Transaction` object.


More specifically, the user can't accidentally let the `Transaction` go out of scope, the compiler would notice and give a compile error. The only remaining option for the user is to move the object somewhere else, or destroy it via `commit` or `rollback`.


Zooming out, you can see how *this struct can only be destroyed by certain explicit operations*, which means we've successfully enabled Higher RAII here.


This mechanism has _huge_ benefits if used well, for example by keeping caches consistent or enforcing we update a database, as I'll list further below.


<slice />

# Why haven't we seen this before?

(Or [skip to the Seven Arcane Uses](#the-seven-arcane-uses))


Existing languages can't quite do this, and I'll show why below.


<slice />

## C++

A C++ class's destructor is guaranteed to be eventually run, so if we ever want to guarantee some future action, we just put the code in an object's destructor (which is guaranteed to run when the object goes out of scope), and keep the object alive until we want that code to run.

Scott Meyers [once said](https://youtu.be/ltCgzYcpFUI?t=937) that "the single most important feature in the language is probably destructors, because destructors have led to the introduction of RAII." [# He goes on to describe how RAII is a general purpose undo mechanism. I would totally agree, except for the way C++ conflated destructors with exception handling. If they didn't use the same function for those two concerns, they could tap into the potential of Higher RAII.]

RAII stands for "Resource Acquisition Is Initialization", a pattern where if you *acquire* a *resource* (such as a file descriptor), you should *initialize* an object with it. Then, the object can make sure to automatically release (such as with `fclose`) the resource when it goes out of scope. [# The hardest thing about RAII is explaining the name. Similar to monads, which are like [stateful burritos](https://byorgey.wordpress.com/2009/01/12/abstraction-intuition-and-the-monad-tutorial-fallacy/).]


Unfortunately, a C++ class can only have one destructor function, and our `Transaction` struct (from above) needs two.


<<<<
A [common half-solution](https://stackoverflow.com/a/10984171/1424454) is to:

 1. Put the above `db` parameter in as a class member `DB* db;`, since C++ destructors have no parameters. Note this isn't always possible. [# This isn't always possible, for example if we don't know the parameter value yet at construction time. Imagine `commit` wanted a `priority` integer, only knowable from reading the database while inside the transaction.]
 1. Have a `commit` method, which also sets a `committed` boolean to true.
 1. In the destructor, run `rollback`'s logic if the `committed` boolean is false.

Alas, this doesn't quite solve the problem because the user still might forget to call `commit` where they should have.
////
```c++
struct Transaction {
  DB* db;
  bool committed = false;

  ...

  // Don't forget to call this!
  void commit() {
    ... // Commit to db
    committed = true;
  }

  // Destructor
  ~Transaction() {
    if (!committed) {
      ... // Rollback logic
    }
  }
}
```
>>>>

<slice />

## Rust

Rust is unfortunately even less capable than C++ here.

Rust can almost do C++'s workaround, but the borrow checker generally dislikes references inside structs, such as that `DB` reference. [# More specifically, Rust structs containing references generally work well as long as they stay within the same function. But at that point, we might as well be using `defer`.]

Rust's workarounds include either using `unsafe`, using `Rc<RefCell<DB>>`, or if one considers those unidiomatic, giving up on RAII. I prefer the second, though I've seen all three happen in the wild.


<slice />

## RAII vs Higher RAII

Summarizing the C++ section above, RAII is the practice of putting code in destructors that you want to guarantee will eventually run.

From that context, we could say that _higher_ RAII is when we can have multiple named destructors, destructors with parameters, destructors with return values, and we can force the user to explicitly call one of them.


Whereas RAII eventually makes us implicitly call a specific zero-arg non-returning function (the destructor), Higher RAII eventually makes us explicitly call _any_ approved function.


! RAII is a terrible acronym, and I am _so, so sorry_ for perpetuating its use. It turns out it's really hard to come up with a name for this concept. [# "Future constraint", "future calling" perhaps? "Vow Objects" maybe? I wish "Promise" wasn't taken.] Feel free to bikeshed in the comments!


<slice />

## What's the difference between RAII and defer?

Go, Zig, and a few other languages have a `defer` statement which will run a statement at the end of the current scope (or function). [#deferzg]

In RAII, we would put that code into an object's destructor, and the code will be run when the object goes out of scope.


They sound like two equivalent approaches, but RAII is more flexible: we can return the object to our caller, so the caller can decide when the destructor is run. Or, we put the object into another object, and the parent object can decide when it's run.

In short: `defer` can make sure something happens at the end of your function, but RAII can make sure that something happens _even past_ the end of your function.


Now that we see the differences between Higher RAII and RAII and defer, let's see some more examples!


<slice>
#deferzg: Zig runs a `defer`'d statement at the end of the scope, as god intended.

Golang is different. For some reason, even if we `defer` from an inner scope, the `defer`'d statement will run it at [the end of the function](https://stackoverflow.com/a/49457047/1424454). This can sometimes lead to surprising out-of-memory crashes.

Golang, I want to love you, I really do, but every time I get used to your latest nonsense you do something like this.
</slice>

# The Seven Arcane Uses [# I call them "arcane" because they seem confusing at first, but once you know the technique, it unlocks some pretty incredible powers. Makes one feel rather... _sorcerous_.] [# Perceptive readers will notice that there's actually eight items here, but seven sounded cooler than eight, and some of them are similar to each other. Besides, everyone already knows I can't count after [the last article](https://verdagon.dev/grimoire/grimoire).]

There are, of course, more than seven ways to use linear types and Higher RAII.

But behold! Here are the seven most useful ones that I've seen.


<slice />

## Cache Invalidation

There are [two hard problems in computer science](https://martinfowler.com/bliki/TwoHardThings.html): cache invalidation, naming things, and off-by-one errors.

Luckily, naming things is a [solved problem](https://sph.mn/dynamic/svn).

But how can Higher RAII help with cache invalidation?


This was the topic of my 2022 article, [Vale's Higher RAII, the pattern that saved me a vital 5 hours in the 7DRL Challenge](/blog/higher-raii-7drl).

I'll try to summarize below, but check out the article for a more in-depth explanation!


My game had two data structures:

 * `levelGoblins List<Goblin>`
 * `locationToGoblinCache HashMap<Location, &Goblin>`

...and they must always be in sync.

*This, of course, had a risk:* I could accidentally remove from the list but not the cache.

So I did two things:

 * Made a `linear struct GoblinInCacheToken`, returned by `addGoblinRefToCache`, and only ever destroyed by `removeGoblinRefFromCache`.
 * Changed `levelGoblins`'s type to `List<(Goblin, GoblinInCacheToken)>`.

Now, removing from `levelGoblins` will give us not only the `Goblin`, but also the linear `GoblinInCacheToken`, and the only way to get rid of the `GoblinInCacheToken` is to hand it to `removeGoblinRefFromCache`.


Suddenly, we've *statically guaranteed* that we'll always remove from both the list and the cache!


<slice/>

## Get the Result of a Thread or Future


C++'s `std::future` (and Javascript's `Promise`) is conceptually a little box that, at some point, will contain the result of some long-running operation. 


For example, let's say that each `Goblin` on our level has a read-only (but expensive!) `determineAction` function.


In this `determineAction`, we want to do two things in parallel:

 * Find a path to the player.
 * Figure out what to shout at the player if there is no path.

That second step will involve calling an LLM on the GPU.


<<<<
Our code could look like this Typescript here.
////
```ts
async function determineAction(
    level: Level,
    goblin: Goblin,
    player: Player) {

  // shoutPromise will eventually contain
  // the result string to shout.
  const shoutPromise: Promise<string> =
    callGPU("taunt", goblin.personality);

  // Some expensive pathfinding
  const path: Location[] =
    findPathAStar(
      level, goblin.loc, player.loc);

  // Bug here!
  return new FollowPathAction(path);
}
```
\\\\
Here, we're sending the goblin's personality array to the "shout" function on the GPU, which runs an LLM.

While that's going, we're doing some expensive pathfinding, to figure out if there's a path to the player.


Then at the end, we return what the goblin should do this turn.


*But wait! There's a bug here!*

We sent the request to the GPU, but forgot to actually _use_ the result.
>>>>


<<<<
After many hours of debugging, we realize the problem, and change that last statement to this code.
////
```ts
  ...
  if (path) {
    return new FollowPathAction(path);
  } else {
    return new ShoutAction(
        await shoutPromise);
  }
}
```
\\\\
This is where Higher RAII could have helped: that `shoutPromise` should have been linear, so we remember to use it.
>>>>


! Some of you might have seen something like this! This is similar to C++'s `[[nodiscard]]`, C#'s `MustUseReturnValueAttribute`, or Rust's `#[must_use]`. However, those are easily foiled: we could e.g. put the result into a List, and then accidentally drop the List. Those measures only look shallowly at the current scope, they don't follow the value through the rest of its lifetime.


I suspect a lot of&mdash;maybe even all&mdash;`Promise`s should be linear.


The stakes are even higher in languages with `async`/`await` where concurrent code doesn't run until we `.await`, because [accidentally dropped Futures can cause concurrency bugs](http://www.randomhacks.net/2019/03/09/in-nightly-rust-await-may-never-return/). A linear `Future` solves that bug nicely.


<slice />

## Remember to Resolve a Future

In C++, you can give a `std::future<string>` to someone, with the understanding that eventually, you will put a `string` into it.


Hopefully you don't forget!


Or, we can use Higher RAII to make sure we remember. Here's how!


<<<<
First, we make a linear type that represents "our vow to put a string into that future".

We'll call it `FutureVow`. [# I wanted to call it `Promise`, because this is literally a linear version of `std::promise`, but I don't want to confuse things with Javascript's `Promise` which is completely unrelated to this.]
////
```vale
linear struct FutureVow<T> {
  future &Future<T>;
}
```
>>>>


Then, we would make sure that whenever we make a `Future`, we also make a corresponding `FutureVow`.

In Vale, that would mean changing `Future`'s constructor to also return the `FutureVow` at the same time, [# Not terribly difficult, just make the default constructor private and then make a new function called `Future` that returns a tuple.] but one can imagine many mechanisms to ensure one is never created without the other.


<<<<
Then, we add a function `set` which consumes our FutureVow.
////
```vale
func set<T>(vow FutureVow<T>, x T) {
  vow.future.set(x);
  destruct vow;
}
```
\\\\
Now there's no way to get rid of a `FutureVow` except by calling this `set` function.
>>>>


Success! Now it's guaranteed that we'll eventually set every `Future`'s value. [# "Guarantee" could be a strong word here. A determined programmer can get around this if they tried hard enough.] [#forgotreturn]


<ignore>
Now that we have the above `determineAction` function, your next task is to implement the `callGPU` function, from the `callGPU("taunt", goblin.personality)` line above.


Your `callGPU` function returned a `Promise`. You're responsible for eventually "fulfilling" the `Promise`, in other words putting the result into it. If you don't, your teammate's code will hang forever.


! Hint: Any time you hear the words "responsible for", it could be an opportunity for Higher RAII!


Generally, if you give someone a Promise, and forget to fill it, it'll manifest as a deadlock, or a hanging program, or a loading spinner that spins forever.


Let's use Higher RAII to make sure we remember!


First, we make a class that represents our responsibility to fulfill the `Promise`. We'll call this new class `Fulfiller`.

! If you're familiar with JS/TS, this `Fulfiller` class would just be a linear wrapper around the Promise's `resolve` and `reject` callbacks.

 * First, we mark our `Fulfiller<T>` class as `linear`.
 * Then, we add a function `fulfill(fulfiller: Fulfiller<T>, value: T)` which takes and destroys the `fulfiller` instance, and fulfills the corresponding `Promise<T>` object.
 * Finally, we make sure that _only_ `fulfill` can destroy a `Fulfiller<T>`.

Now, it's impossible to forget to fulfill a promise!
</ignore>


<slice>
#forgotreturn: `async`/`await` also helps to prevent this bug in some cases. With `async`/`await`, we don't manually resolve a future, we `return` a value instead, and compilers are pretty good at preventing forgotten `return` statements.

However, there are times in `async`/`await`-enabled languages where we still use raw futures, such as the `callGPU` example above.
</slice>

## Prevent Zombie Temporary States

By day, my computer helps me write articles like this one.

But by night, it [uses an LLM to crawl the internet searching for sufficiently weird yearly events](/blog/llm-throughput-not-ram-limited), such as:

 * [Corgi Races](https://tickets.canterburypark.com/events/2023/corgi-dog-races) in Minnesota. [Go Logan Handsomepants!](https://youtu.be/tPuKyeVsfZY?t=93)
 * [Flora-Bama Mullet Toss](https://www.florabama.com/mullet-toss) where people in Florida throw fish into Alabama!
 * [Outhouse Races](https://visitvirginiacitynv.com/events/world-championship-outhouse-races-virginia-city/), which is... hard to explain.


Every time it finds a possible event, it adds it to the `Event` list.

Then, we do some [retrieval-augmented generation](https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/) by googling for information about the event, analyzing each result with an LLM, and coalescing the relevant pages into a summary, updating the `summary` field and making it visible on the map.


Alas, this was in Python, so *I had a bug: I forgot to update the* `summary` *in some cases.*

This struct was forevermore stuck in its temporary `summary`-less state, like some sort of zombie stuck between one realm and the next. And since I only show `summary`'d events on the map, it took me a while to realize a lot of events were missing.


If Python had Higher RAII, I could have prevented this bug!


<<<<
Here's how Vale would do it:


First, we'd split our struct into two structs, `InProgressEvent` and `Event`.


Then, we'd make a `finish` function to consume the `InProgressEvent` and return a new `Event` object with the new `summary`.


Suddenly, we're guaranteed to eventually give our `InProgressEvent` to `finish` to properly make it into an `Event`!
////
```vale
linear struct InProgressEvent {
  name str;
}
struct Event {
  name str;
  summary str;
}
func finish(
    event InProgressEvent,
    summary str) {
  [name] = destruct event; «destructure»
  return Event(name, summary);
}
```
>>>>


! Savvy metaprogrammers would recognize the above as a kind of [type-state pattern](https://cliffle.com/blog/rust-typestate/). [# In the type-state pattern, we split one struct into many, to more closely match the data's state machine diagram.] Higher RAII completes the type-state pattern, by forcing the developer to drive the state machine to its final state.


I also could have used Higher RAII to make sure the tool always reflected its findings into the database. As it is now, the database contains six zombie in-progress events... I let them remain, to remind me why I need to translate the tool to Vale.


<slice>
#destructure: `[name] = destruct event;` is just putting `event`'s old members into new local variables, in this case `name`.
</slice>


## Remember to Handle Messages

Let's say you have thread A and thread B.

How does thread A ask thread B to run a certain function `foo`?


You're probably thinking, we should have thread A send a `FooMessage` of some sort to thread B, and then thread B can handle it and call `foo`.

That works, but what if thread B accidentally forgets to call `foo`, and lets the `FooMessage` go out of scope? We'd have a bug.


Higher RAII can help with this: we would make `FooMessage` linear, and make it so only `foo` can destroy it.

Now, if thread B receives a `FooMessage`, it can't forget to call `foo` on it.


I suspect a lot of&mdash;maybe even most&mdash;messages should be linear.


Also, if we send a `linear` message through a channel, the channel's receiving end needs to be `linear` as well. That's a good thing, because it forces us to handle all remaining messages before we drop the receiver.

This serendipitously solves some missed-message concurrency bugs that e.g. Golang channels and [Tokio channels](https://docs.rs/tokio/latest/src/tokio/sync/mpsc/chan.rs.html#523) [#tokiochannels] are vulnerable to.


<slice>
#tokiochannels: In [chan.rs](https://docs.rs/tokio/1.37.0/src/tokio/sync/mpsc/chan.rs.html#523)'s `Chan::drop`, the `while` loop drains the incoming message list and just drops them on the floor. Those poor forgotten messages!
</slice>

## Remember to Make a Decision

In the Higher RAII explanation above, we showed how we could make a `Transaction` object that can only be destroyed via a `commit` or a `rollback` function.


Let's include that in our Seven Arcane Uses, and even generalize it a bit: *If there is a future decision to be made, Higher RAII guarantees that we'll eventually make it.*


I sometimes wish there was something like this for real life.


"Evan, think you're going to cancel that membership?"

"Don't know, still thinking about it."

"How long do you plan on thinking about it?"

"Probably until after it automatically renews."


Alas, I didn't make the decision, and so the default action was taken: my membership was renewed.

Truly, life would be better with Higher RAII. [#halp]


<slice>
#halp: No! The grimoire is compelling me to write this article and spread *the curse.*

Heed my words, _never use Higher RAII,_ lest you be cursed to see all the places in other languages' code where it could have been used to prevent a bug.

Every time you see the words "remember to", "forget", or "responsible for" in comments or design discussions, you'll see another place that Higher RAII could have helped.

Even among friends you will be alone, the only one able to see the spirits of bugs prowling, knowing their inevitability yet being powerless to prevent them, [limited by the technology of your time](https://www.youtube.com/watch?v=6AcbHiJtbcM). Such is the curse. Such is our fate.

I hesitate to spread it to you, my dear readers, but I am compelled by the grimoire and am powerless to stop. I takes all my strength to merely put this side note in, hoping that someone sees it and spreads my warning.
</slice>

## Prevent Leaks

We all know that manually-managed-memory languages (like C) can leak memory, from forgetting to call `free`. We also know that reference-counted languages can leak memory, from reference cycles.


Did you know that *even garbage collected languages* (like Java) [can have memory leaks too](https://stackoverflow.com/a/10619408/1424454)?

Imagine the above cache invalidation example in Java: the forgotten `Goblin` reference in the `HashMap<Location, Goblin> locationToGoblinCache` will prevent the GC from reclaiming it, effectively "leaking" it.

So we can already see how Higher RAII could help with leaks, by preventing that kind of accidental outstanding strong reference.


Of all the mainstream languages, I'd say modern C++ is the most resistant to memory leaks, and you'll see why.


Surprisingly, Rust can be *more vulnerable to memory leaks* than C++! I'll show you what I mean by translating a C++ Red-Black tree to idiomatic Rust, and how it introduces the risk for memory leaks.


<<<<
Let's say you have this C++ Red-Black Tree node class.
////
```c++
template<typename T>
class RBNode {
public:
  T data;
  unique_ptr<RBNode<T>> left;
  unique_ptr<RBNode<T>> right;
  RBNode<T>* parent;
  Color color;
};
```
\\\\
This has an implicit destructor. When we delete a node, the destructor will automatically delete (and call the destructors for) its `left` and `right` children.
>>>>


<<<<
Now let's translate this to Rust. The borrow checker doesn't like it when a node can be pointed at by multiple places, so we'll *"collectionize"*: we'll put all these nodes in a collection, a HashMap, and have nodes refer to each other by `u64` IDs.
////
```
struct RBNode<T> {
  data: T,
  color: Color,
  parent: Option<u64>,
  left: Option<u64>,
  right: Option<u64>,
};
```
>>>>


We would store all these nodes in a `HashMap<u64, RBNode<T>>`, and separately keep track of which is the root node.

This is great! There's no way to use-after-free, which was a potential problem in the C++ version.


However, we've just *introduced another possible bug.*

Remember how when we delete a C++ node, its destructor would automatically delete the node's children?

Unfortunately, that doesn't happen anymore in the Rust version. Rust doesn't automatically remove from a hash map when we drop a `u64`.

This can lead to "orphaned" nodes. This memory is "leaked" until the parent `Vec` goes out of scope, similar to how Java can leak objects.


The problem is more widespread than we think. Just like above, Rust programs *naturally tend to collectionize* [# See also [1vader's insightful comment](https://www.reddit.com/r/rust/comments/1azbdb8/comment/ks0huy0/) about this natural collectionization and its benefits and drawbacks.] because the borrow checker generally dislikes when multiple long-lived references point to the same object. [# More precisely, the borrow checker generally doesn't allow us to ever modify something if anything else has a reference to it.]

We end up with architectures where a lot of collections' structs have IDs referring to other collections' structs *instead of owning things directly*. The result is often similar to an entity-component-system architecture [# For more benefits and drawbacks of this natural collectionization, also check out this post on [EC vs ECS in Roguelikes](https://www.reddit.com/r/roguelikedev/comments/i3xekn/ec_vs_ecs_for_roguelikes/?rdt=44855).] or a relational database. [# At least relational databases have `ON DELETE CASCADE`, which is kind of like an owning reference if you think about it.]

With this collectionization, the risk for this kind of "memory leak" increases.


But Higher RAII can help!


Let's pretend Rust has a `linear` keyword, and see what happens.


<<<<
We'll make a linear `OwningIndex<T>` struct containing an index. The `OwningIndex` struct conceptually owns the `RBNode` its index refers to.

We also made `RBNode<T>` linear because only a linear struct can contain a linear struct. In fact, that Option<OwningIndex> is also implicitly linear.

Finally, we make it so only one place can destroy an OwningIndex<T>: the `remove_node` function.
////
```linear-rust
linear struct OwningIndex<T> {
  index: usize;
}
linear struct RBNode<T> {
  data: T,
  color: Color,
  parent: Option<usize>,
  left: Option<OwningIndex>,
  right: Option<OwningIndex>,
};
```
>>>>


This solves the problem! Though it can be hard to see why, so I'll try to explain:

 * When we destroy a `RBNode<T>` instance, we're forced to take ownership of each child `Option<OwningIndex>` instances.
 * The only way to get rid of an `Option<OwningIndex>` is to `match` it into either a (non-linear) `None` or a (linear) `Some<OwningIndex>`.
 * The only way to get rid of a (linear) `Some<OwningIndex>` is to destruct it, taking ownership of the contained `OwningIndex`.
 * The only way to get rid of an `OwningIndex` is hand it to `remove_node` (or, we could stuff it into another `RBNode<T>`).


In short, the language forces us to eventually deliver that `OwningIndex` to another node or to call `remove_node`.


<ignore>
TODO: generalize
</ignore>


<slice />

## Solve lookup-after-remove

Our final Arcane Use is to prevent a certain common logic bug.


In C++, if we don't own a `Spaceship` but we want to access it, we store a pointer `Spaceship*`. If we destroy the `Spaceship`, the `Spaceship*` becomes "dangling" and dereferencing it causes a use-after-free bug.

When we translate that code to Rust, the usual outcome is that we instead store a `u64` "Spaceship ID", which is the key into a central `HashMap<u64, Spaceship>`. We would "dereference" the ID by calling `the_hash_map.get(spaceship_id)`.

Unfortunately, the bug is still here, but in a different form: if we remove the `Spaceship` from the map, and _then_ call `get` with that "dangling" u64, we receive a `None` which likely represents a bug. In other words, Rust turned the use-after-free into a "lookup-after-remove" bug.


Higher RAII can help with this.

Let's make a special `LinearHashMap` with these three adjustments:

 * `insert` takes a key (`u64`) and a value (`Spaceship`) and returns a `LinearKey` which is simply a linear struct containing the key.
 * `get` takes a `&LinearKey` and returns a reference to the value (`&Spaceship`).
 * `remove` takes ownership of the `LinearKey`, destroys it, and returns the value (`Spaceship`).


`get` can return a `&Spaceship` instead of an `Option<&Spaceship>` because if the given `LinearKey` still exists, then we know that the `Spaceship` is still in the hash map.


This isn't _completely_ immune to problems: we'd still have a bug if we give one map's LinearKey to another map, and a language that can recover from panics will have weakened guarantees here. [# Specifically, some panic unwinding might destroy either the hash map or the key, causing a mismatch.] Solving these will require a little more effort. [#keysolns]


! This is kind of similar to the cache invalidation example. In the cache invalidation example, we used Higher RAII to enforce consistency between two maps. In this example, we're using it to know an ID isn't dangling.


This particular use case shows an ability with much larger implications, and allows a lot of *spooky knowledge at a distance.* [# A taste: Here, some code can see that the LinearKey exists, and know that the corresponding object still exists. This technique can be used to, for example, elide generation checks and eliminate many classes of errors.] If you follow this curséd path, you'll eventually arrive at the nebulous "linear reference counting" concept I hinted at in [the grimoire](/grimoire/grimoire). [# A hint: We can use the existence of a linear reference as proof that the pointee object still exists, because the object can't be destroyed until the linear references are returned to it.]


By the way, also check out Niko Matsakis's [blog post](https://smallcultfollowing.com/babysteps/blog/2023/03/16/must-move-types/) on what it would look like if Rust had linear "must-move" types! [# See [this StackOverflow answer](https://stackoverflow.com/questions/71694803/rust-type-that-requires-manual-drop) for a clever hack to make some types linear!]


<ignore>
# Spooky knowledge at a distance

Higher RAII is powerful, as we can see. However, I suspect there's something even more powerful hidden here somewhere. I'll try to explain.


In Higher RAII, we know that *if we make a linear struct, we can guarantee some future action.*

However, we also know something more: *if a linear struct exists, we know that that future action hasn't happened yet.*


In that last example, `get` uses the `&LinearKey`'s existence to assume that it refers to a value that still exists in the map.

In other words, it sees the `&LinearKey` and knows that `remove` hasn't happened yet, because `remove` destroys the `LinearKey`.


We've already seen how we can use Higher RAII to guarantee some future action. Here, Higher RAII is _also_ informing us that some future action (`remove`) _hasn't happened yet_, and therefore that something (`get`) is safe to do.


This seems like some sort of *spooky knowledge at a distance*. I can't quite wrap my head around it, but I suspect there could be some pretty big implications.


This _might_ also include the "linear reference counting" idea mentioned in [the grimoire](/grimoire/grimoire). It feels similar. It makes me wonder if there's some more general power here, waiting to be found. Hopefully we'll uncover more ancient Mayan tomes that can illuminate this.
</ignore>


<slice>
#keysolns: For the first problem, we can make the LinearKey bound to the map's lifetime, or we can use an assertion, or make a different type for every map, or there are a few other solutions out there.

The second problem isn't so bad, but `get` might want to panic if the key isn't found. I _suspect_ there's other solutions here that could prevent this problem.
</slice>

# Can other languages add Higher RAII?

Yes! It generally fits most cleanly into single-ownership-based languages (C++, Rust, Austral, Mojo, Carbon, CppFront, etc.), and Haskell shows us that GC'd languages could have luck too.


To walk this path, there are some steps a language has to follow.


First, let's address *exceptions, panics, and async cancellation*. The reason that regular RAII requires a zero-argument destructor is that an in-flight exception (or panic, or `async` task cancellation) will unwind the stack, destroying everything in its path. [# Exceptions are rather rude, aren't they? You're just having a nice time talking with your fellow local variables and then an exception bursts into the room and starts destroying everything.] To do this, it calls a zero-argument destructor or `drop()` function. So what does an in-flight exception do for a linear type?

The answer: we can add a separate `onException` function for any linear type; we don't have to conflate exception handling with destructors. This `onException` would take ownership of the type and attempt to correctly dispose of it. One can imagine a few other mechanisms to help with this too. [#onException]


<slice>
#onException: Even though this whole scheme is a big improvement, `onException` would still be a zero-arg no-return-value function, which is a similar challenge as RAII's destructors. We could:

 * Allow `onException` to return data, which is collected and processed later somehow.
 * Have the thread register a `onExceptedLinearStruct` function which introspects the type of the given linear type, and specially handles it.
 * Last resort, add it to a global list for handling later.

But even without these measures, we've still reduced the problem drastically and enabled Higher RAII, which is an improvement.
</slice>


Second, *when dealing with generics* (like the `T` in `List<T>`), they need to take out the assumption that `T` has a destructor or a zero-argument `drop()` function.

This can require some standard library changes: a function like [std::vector<T>::pop_back](https://en.cppreference.com/w/cpp/container/vector/pop_back) becomes problematic, it assumes it can just destroy the popped element.

In Vale, that function instead returns the popped element, so the caller can decide what to do with it.

As [Aria Beingessner wrote](https://faultlore.com/blah/linear-rust/), this is the main reason that Rust would have difficulty adding linear types: the entire existing ecosystem already assumes that it can drop given types. [# The rest of their post is really good too. Though my experience with Vale shows me that linear-type-enabled generics are more ergonomic than they suggest, once you have the right patterns in place.] [#valerust] The same would likely apply to C++.


Third, *reconcile it with the aliasing* introduced by reference counting or garbage collection. One would assume that a reference-counted type can't have Higher RAII, but that's not true: we just need a single reference to be designated as the linear reference. This is similar to how `unique_ptr`, constraint references (from [the grimoire](/grimoire/grimoire#the-list)), and generational references work: one reference is a special "owning reference".


Fourth, *figure out globals*. There's a lot of potential solutions to this one, [# I'm curious about potentially requiring `main` to initialize and destroy globals explicitly, and call the "global constructors" for all dependencies (which would presumably then call _their_ dependencies' global constructors and so on). Lot's of interesting benefits and drawbacks to explore on that one.] for example just requiring all globals be non-linear, or requiring a destroyer function for any linear globals. [# Last resort, one can just make the global an `Option`, empty it from inside `main`, and have the global's destroyer function just assert it's empty.]


Fifth, *[send me an email](mailto:verdagon_epsa@verdagon.dev)*, because there's a lot of interesting hidden design decisions to be made about whether a _type_ is linear, or our _usage_ of a type is linear.

These design decisions go straight to the original definition of linear types and affect, for example, whether `linear struct` literally means "a linear struct", or whether it just means "a `drop()`-less struct", a subtle distinction that can have quite a few benefits and tradeoffs.

I hope to write an article about this at some point, but I am compelled by unholy sorcery to complete [the grimoire](/grimoire/grimoire) first.


<slice>
#valerust: Though, ironically, there's a chance that by adding Vale's Rust FFI, I might be indirectly adding Higher RAII to Rust: I _may_ have found a way that Vale can automatically and seamlessly call directly into Rust libraries, without user-written bindings, even though Rust doesn't have a stable ABI.

It would have some interesting constraints:

 * We'd only be allowed to put non-`linear` Vale structs inside Rust structs.
 * If we reinterpret a Rust struct as linear, we wouldn't be able to move it into a Rust function (which might `drop` it).

but if it works, then Vale could just reinterpret external Rust types as linear, or wrap the external Rust types in linear Vale structs. I hope to prototype this over the next several months, so stay tuned!
</slice>


# Higher RAII: The missing piece toward correctness

A major implication of Higher RAII is that it can bring a language's programs much closer to the ever-elusive goal of *correctness*.

Correctness is [two things put together](https://www.hillelwayne.com/post/safety-and-liveness/):

 * Safety: the assurance that "bad things don't happen", for example, a panic, a crash, or a use-after-free.
 * Liveness: the assurance that "good things _do_ happen", for example a plane lowering its landing gear.

Safety helps liveness: a panic'd subsystem can't lower the landing gear. And liveness helps safety too, as we saw in our lookup-after-remove example. Like [classical and techno](https://www.youtube.com/watch?v=wZPOUR3A24k), the two blend and build upon each other in surprising and interesting ways.

Alas, no languages have nailed liveness yet. [#valecorrect]


But there's hope! Linear types and Higher RAII help with liveness and correctness.

There are two languages that could really shine here: *[Mojo](https://www.modular.com/)* and *[Austral](https://austral-lang.org/)*, both which use an easier form of borrowing for memory safety and speed.

Austral is using linear types today, and the Mojo folks are now looking into adding linear types to Mojo as well.

If they can harness this power well, they could bring correctness to the mainstream in a way that's simple enough to not require users to learn advanced category theory. And that's a _huge_ deal.


<slice>
#valecorrect: I think Vale is _close_ in this regard, but not quite there yet. One can accomplish this in Vale with [move-only programming and regions](/blog/linear-types-borrowing), but that technique is even harder to use than borrow checking.

A lot of my nights are spent chasing a certain holy grail: blending borrow checking with Vale's existing hybrid strategy. This quest has singlehandedly led to half of the grimoire!
</slice>

# Software Architecture Implications

It wouldn't be a Languages ∩ Architecture blog without considering the architectural implications of a feature!

So how does Higher RAII do?

Aside from all the above powers, there's three more benefits and a drawback as well.


<slice />

## Benefit: Makes stateful future changes explicit

The first benefit is that Higher RAII *helps our code be explicit.* This is better than regular RAII which implicitly and invisibly changes the state of the program.

This is so important that one of Zig's core principles is that [there should be no hidden control flow](https://ziggit.dev/t/what-does-zig-mean-by-no-hidden-control-flow/3618). Higher RAII means we can get RAII's benefits without that hidden control flow.


<slice />

## Benefit: Makes your API twice as easy to use correctly

The second extra benefit is that a function can help your future self, not just your past self.

Today's languages already make it easy to control the past: `second(f)` can require that you first call `first()`, by taking in a parameter`f` that only `first` returns.

However, this is one-sided. `first()` has no control over whether we ever call `second()`. We solve that with Higher RAII, by making that intermediate type `linear`.

In other words, *Higher RAII makes it twice as easy to use your API correctly.*

When working on a team, this is a major boon. You can now reach across space and time to help your teammate remember to call `teardown(thing, 3, true)`.


<slice />

## Benefit: Less fear to refactor

The third benefit is that by eliminating a certain class of errors, we give ourself *more freedom to refactor and improve* the codebase.

I explain this nebulous concept in [How To Survive Your Project's First 100,000 Lines](/blog/first-100k-lines), but I'll summarize:

 * It's easier to change your program if you have tests: you can know that your change isn't breaking the program in unexpected ways.
 * It's easier to refactor Java than Python, because Java's static typing means the compiler can sanity check everything you've changed.
 * In Java, you can harness the type system a little bit, or a lot. Leaning on it more is generally better.

Adding higher RAII is another step in this direction: it sanity checks that your modified code actually _did_ remember to call everything it was supposed to.

This strengthens the codebase and makes it more resilient to bugs, which means we're less afraid to do refactors and other long-term investments.


Higher RAII has the above three benefits, but it also has a drawback.


<slice />

## Drawback: `linear`ity can be viral

The first drawback is that `linear`ity is an *upwardly viral constraint* on our data, in that it can impose requirements on those who contain it.

For example, if a `Spaceship` is `linear`, then so is `List<Spaceship>`, and likely anything that contains it, such as a `Shipyard`. [# Or, if struct `Outer` contains `linear struct Inner`, then `Outer` will likely need to be linear as well, because `Outer`'s auto-generated `drop()` function doesn't know what to do with `Inner`.]

This isn't necessarily a problem, unless you're adding a `linear` member to an existing non-`linear` struct: it could case an inconvenient refactor.

! Other "upwardly viral constraints" include `async`/`await` [#async] and Rust's borrow references, [#borrowing] though those are more about functions, not data.

This drawback can be mitigated by instead defining a custom `drop()` for the `Shipyard`, if it has the necessary data to call some other function to destroy the `Spaceship`s, but that's not always possible.


<slice>
#async: See Bob Nystrom's [What Color is Your Function](https://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/) article.

Though sometimes, a normal function can still call an `async` function and instead put the resulting Future onto a list somewhere instead of `await`ing it.

#borrowing: When we have a `&mut` in Rust, we usually need to get it via a parameter. This imposes the restriction on our caller, and all our callers' callers, that none of them have a reference to this object.

Fortunately, we can mitigate the upwardly viral spread with `.clone()`s or reference counting, though both can have performance implications.
</slice>


<ignore>
# Linear Types' Future

There are a few languages with linear types, most notably [Haskell](https://ghc.gitlab.haskell.org/ghc/doc/users_guide/exts/linear_types.html), [Vale](https://vale.dev/), and [Austral](https://austral-lang.org/linear-types), and only Vale has gone further and added Higher RAII.


I personally hope that a lot more languages add linear types and Higher RAII... but it's not as easy as it sounds.


It's not hard to get basic linear types working:

 * Never let a linear struct go out of scope.
 * Only a linear struct, linear array, or a local variable may contain a linear struct.


But in Vale, I wanted to *avoid viral data coloring*

But there are some things  hard part is making linear types mesh well with the rest of the ecosystem.

The hardest part is making it compose well with the rest of the ecosystem. For example, 
</ignore>


<slice />

# That's all!

One reason I love making languages is that I get to play with and write about new techniques and share their implications with the world. I didn't realize it at the time, but I've been playing with Higher RAII since my [very first article](/blog/raii-next-steps#language-implications) four years ago.


After using it and seeing its potential, it's become a central feature of Vale, manifesting its benefits in user-space programs, the standard library, and even some aspects of Vale's memory safety approach.


There's so much more I could write about them! But alas, this one is almost... oh wow, 19 pages. Congrats on getting to the end!


I hope you all enjoyed this post! I'm grateful to have all of you to share this arcane nonsense with. If you have any questions, always feel free to reach out via [email](mailto:verdagon_epsa@verdagon.dev), [twitter](https://twitter.com/vale_pl), [discord](https://discord.gg/SNB8yGH), or the [subreddit](https://reddit.com/r/vale).


Donations and sponsorships for Vale are currently paused, but if you like these articles, please [Donate to Kākāpō Recovery](https://www.doc.govt.nz/kakapo-donate) and let me know! I love those birds, let's save them!


Cheers,

- Evan Ovadia


<slice new-color="afterword"/>

# Thank you!

I want to give a huge thanks to [Arthur Weagel](https://github.com/aweagel), [Kiril Mihaylov](https://github.com/KirilMihaylov), [Radek Miček](https://github.com/radekm), [Geomitron](https://github.com/Geomitron), [Chiuzon](https://github.com/chiuzon), [Felix Scholz](https://github.com/soupertonic), [Joseph Jaoudi](https://github.com/linkmonitor), [Luke Puchner-Hardman](https://github.com/lupuchard), [Jonathan Zielinski](https://github.com/tootoobeepbeep), [Albin Kocheril Chacko](https://github.com/albinkc), [Enrico Zschemisch](https://github.com/ezschemi), [Svintooo](https://github.com/Svintooo), [Tim Stack](https://github.com/tstack), [Alon Zakai](https://github.com/kripken), [Alec Newman](https://github.com/rovaughn), [Sergey Davidoff](https://github.com/Shnatsel), [Ian (linuxy)](https://github.com/linuxy), [Ivo Balbaert](https://github.com/Ivo-Balbaert/), [Pierre Curto](https://github.com/pierrec), [Love Jesus](https://github.com/loveJesus), [J. Ryan Stinnett](https://github.com/jryans), [Cristian Dinu](https://github.com/cdinu), and [Florian Plattner](https://github.com/lasernoises) (plus a very generous anonymous donor!) for sponsoring Vale over all these years.

Your support has always given me the strength and resolve to explore these arcane corners of the world. And even though I'm not doing sponsorships for a while, it's awesome to know you're with me in spirit. [Axes high!](http://www.gamesurge.com/pc/strategy/pc_wt/Adom.shtml)



<ignore>
# The Curse of Knowing Higher RAII

Knowledge is power, and sometimes also a curse.

Never read the [essays of rationality](https://www.lesswrong.com/posts/WusBwpQL5bMgdZtmz/some-of-the-best-rationality-essays), [# And never read [Harry Potter and the Methods of Rationality](https://hpmor.com/) ([audiobook rss and mp3](https://hpmorpodcast.com/?page_id=56)) for the same reason.] or you'll suddenly see everywhere the flaws and imperfections of our ways of thinking, and ever be pulled toward a better self.

Never learn how to [build a programming language](https://craftinginterpreters.com/), or you'll be lost wandering the forgotten realms of programming possibilities for a decade or more. [# Definitely not speaking from experience here.]

</ignore>


<ignore>



But alas, it's 1:30am, and I'm starting to 



# Open Questions

TODO finish this section

Someone should give you a linear struct if they expect you to:

 * Call a callback.
 * Log something.
 * Write something to a database.
 * Send an HTTP request to some telemetry server.


TODO finish this

I hope you enjoyed this article!

[Save the kakapos](https://www.doc.govt.nz/kakapo-donate)!





   * what % of bugs could have been prevented with Higher raii?
     * probably depends on how many things can be represented by linear RC.


Some real-world examples of linear types:

 * A cafeteria tray can be a linear type: you aren't allowed to leave it on the table, you must eventually return it to somewhere, or give it to someone else who will.
 * A JIRA ticket that's assigned to you; you can't just ignore it, you must eventually resolve it somehow or assign it to someone else.
 * A baton in a relay race: you can finish the race with it, or you can hand it off to someone else.





For example, you have three very large numbers. For each large number, you want to fire up a thread that will call `biggestPrimeFactor(x)` for each one.


<<<<
You might do something like this:
////
```c++
int biggestPrimeFactor(int n) {
  ...
}

vector<int> foo(vector<int> numbers) {
  // Result numbers will eventually be put
  // into these futures.
  vector<future<int>> futures;

  for (int x : numbers) {
    // Call biggestPrimeFactor on a thread
    futures[i] =
      async(
        launch::async,
        biggestPrimeFactor,
        x);
  }
  // Now, many threads are calculating.

  // Wait for and receive from each future
  vector<int> results;
  for (future<int> fut : futures) {
    int result = fut.get(); // Waits
    results.push_back(result);
  }

  return results;
}
```
\\\\
Here, `foo` takes in many large numbers, for example 185395729470, 383495729470, and 15935205.

The biggest prime factor for each of those respectively is 32779, 16551391, and 23, so `foo` returns those.

Note how we need to call `fut.get()` to wait for and receive the result of the future.
>>>>


We often receive futures and 


When you receive a future, the result is probably not in there yet. It will be in the future, though!


<<<<
For example, let's say we have a very large number like `185395729470`, and we want to calculate the smallest numbers that can be multiplied together to get this number.

In this case, `2 x 3 x 5 x 7 x 23 x 1171 x 32779` are the numbers that multiply together to become `185395729470`.
////
```c++
vector<int> primeFactors(int n) {
  vector<int> factors;
  for (int i = 2; i <= n / i; i++) {
    while (n % i == 0) {
      factors.push_back(i);
      n /= i;
    }
  }
  if (n > 1)
    factors.push_back(n);
  return factors;
}
```
>>>>




 </ignore>



<ignore>
expand in another article:

### Type-State Pattern

Let's show another example of the type-state pattern, and then show how Higher RAII unlocks its next step.


Imagine a struct that has states and also has methods that make sense for certain states.

For example, we have a `TaxReturn` struct with a `status` enum, which has:

 * `submit` methods for when `status` is `IN_PROGRESS`.
 * `track` and `approve` methods for when `status` is `SUBMITTED`.
 * A `close` method for when `status` is `APPROVED`.


Instead of having one struct with three methods, we would have three structs with one method each, shown in Rust below.

<<<<
We would divide the one struct...

```rust
enum Status {
    InProgress,
    Submitted,
    Approved,
}
struct TaxReturn {
  status: Status,
  ...
}
impl TaxReturn {
fn submit(&mut self) {
  assert_eq!(
    self.status, Status::Instatus);
  ...
  self.status = Status::Submitted;
}
fn track(&self) {
  assert_eq!(
    self.status, Status::Submitted);
  ...
}

fn approve(&mut self) {
  assert_eq!(
    self.status, Status::Submitted);
  ...
  self.status = Status::Approved;
}

fn close(self) {
  assert_eq!(
    self.status, Status::Approved);
  ... // Some very important code
  // return nothing
}
}
```
////
...into three structs:

```rust
struct InProgressTaxReturn { ... }
fn submit(self: InProgressTaxReturn)
-> SubmittedTaxReturn {
  ...
  return SubmittedTaxReturn { ... };
}

struct SubmittedTaxReturn { ... }
fn track(self: SubmittedTaxReturn) {
  ... // Print tracking information
}
fn approve(self: SubmittedTaxReturn)
-> ApprovedTaxReturn {
  // No assertion needed!
  ...
  return ApprovedTaxReturn { ... };
}

struct ApprovedTaxReturn { ... }
fn close(self: ApprovedTaxReturn) {
  ... // Some very important code
  // return nothing
}
```
>>>>

And suddenly, it's *impossible to call the wrong method at the wrong time:*

 * We can only call `submit` on an in-progress tax return.
 * We can only call `track` or `approve` on a submitted tax return.
 * We can only call `close` on an approved tax return.

This is the power of the type-state pattern!


In general, the type-state pattern is where we divide our one struct into multiple, have functions to transform from one to the other, and only make certain functions available for whatever structs make sense.


However, *without linear types, there is a problem.* Let's diagram the above as a state machine.

<<<<
One would assume it's like this:

<img src="/images/TypeStateProgrammingLie.png" width="100%"/>

(this is incorrect)
////
However, this is more accurate:

<img src="/images/TypeStateProgrammingTruth.png" width="100%"/>

(this is more accurate)
>>>>


Note the red dashed lines. These are unfortunately possible, because these structs aren't linear; we can `drop()` them at any time.


This can lead to pretty serious bugs, especially since we never got to call that `... // very important code` in `close()`.


As you can see, today's languages don't do the type-state pattern that well, because *they always allow an implicit extra transformation*, specifically they allow us to transform the struct into nothing, by allowing the struct to go out of scope.


*Higher RAII is the missing piece* for the type-state pattern; it eliminates that unwanted extra possibility.


All we need to do is make these structs `linear` and the problem goes away.


Adding Higher RAII to the type-state pattern feels like adding null safety to a type system: by removing an unwanted extra possibility, we reduce the odds of bugs very nicely.


(then another follow up article: safety and liveness)
</ignore>


<ignore>
If they they can blend Higher RAII with their [simplified borrowing](https://youtu.be/JRcXUuQYR90?t=3055) system, then it could be the language that brings correctness to the mainstream in a way that's simple enough to not require a degree in category theory. And that's a _huge deal_.

I might be biased because their simplicity philosophy agrees with my own (flatten the learning curve [#flattencurve] to bring safety and speed to the mainstream [#healdivide]) but 

#healdivide: From Chris Lattner's [Developer Voices interview](https://youtu.be/JRcXUuQYR90?t=2312), they want to "*heal this divide* between all the different personas building these systems," referring to the various high- and low-level people in the space.

#flattencurve: For example, in Mojo you can basically start with dynamically-typed Pythonic code, and then [progressively add](https://youtu.be/JRcXUuQYR90?t=1853) optimizations. This is the same philosophy that led to region borrowing's [opt-in design](/blog/zero-cost-borrowing-regions-part-1-immutable-borrowing#looks-familiar).

> In Mojo, \[borrow references\] are way less in your face, you don't have to micro-manage the borrow checker quite as much, but it provides you the same approach and ability to manage references. ... 
</ignore>

