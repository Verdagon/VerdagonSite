---
title: Implementing a New Memory Safety Approach, Part 7
subtitle: Results and measurements!
author: Evan Ovadia
date: Jul 12, 2023
realm: blog
path: blog/making-regions-part-7-results
layout: annotated
namespace: c-blog m-annotated
sponsor: us
---

At long last! We arrive at the final step of this endeavor.


Three years ago, I came up a couple weird ideas:

 * What if we use generational indices as the foundation for an entire language?
 * What if the compiler could track which data existed before this pure call?


Those two ideas evolved in _weird_ ways. The first one become [generational references](/blog/generational-references) and the second evolved into a full [region-based borrowing system](https://verdagon.dev/blog/zero-cost-memory-safety-regions-overview) to give us another way to eliminate generation checks. Together, these looked like they could form an entirely new approach to memory safety!


What made all this exciting was that it's a completely opt-in system; we could write our code in a normal, comfortable way, and then come back and add regions later for the parts of our program that we want to optimize. Even with just the most basic form of regions (via [pure functions](/blog/zero-cost-memory-safety-regions-part-1-immutable-borrowing)) we could reduce most generation checks away with just a few annotations, which is an amazing return on investment. Between that, [isolates](/blog/zero-cost-memory-safety-regions-part-2-isolates), and linear style, [# Linear style is where we never make a reference to something unless handing it into a pure function.] we can get generation checks **down to zero.**


Most of my free time for the past years has gone into building out the Vale compiler's foundations so that they could support this crazy approach. It was _hard_. Region borrowing is already pretty complex under the hood, but it also requires generics, which are notoriously difficult. [# It took the Golang team a decade to figure out their generics, and I don't blame them at all for that, after this struggle with generics!] Not only that, but to get regions and generational references to work seamlessly together required a completely new way of thinking. [# Under the hood, it reduces regions to "pure height" integers: negative for region generic parameters, zero for the default region, and increasing positive for every pure block. This required an entire extra stage in the Vale compiler. See Part 4 for more on this!]


A few months ago, I finished the regions prototype. It's rough around the edges, [# For example, its compile errors are very, _very_ verbose, and there are a lot of things that just trigger assertions in the compiler still.] but it successfully compiles Vale programs.


With that prototype completed, the [first ever zero-check Vale program was born](https://github.com/Verdagon/RegionsBenchmarks/blob/main/cellular-automata/CellularAutomata.vale). It was a little [Cellular Automata](https://gamedevelopment.tutsplus.com/tutorials/generate-random-cave-levels-using-cellular-automata--gamedev-9664) algorithm, one commonly used to generate cave levels in games.

<div style="position: relative; width: 128px; margin: auto">
<style>
.fade {
  animation-iteration-count: infinite;
  animation-timing-function: linear;
  animation-duration: 8s;
}
.fade-in-1 {
  opacity: 1;
  animation-name: fadeIn1Opacity;
}
.map-image {
  width: 128px;
  height: 128px;
  image-rendering: pixelated;
}
@keyframes fadeIn1Opacity {
  0%   { opacity: 1; }
  27%  { opacity: 1; }
  33%  { opacity: 0; }
  62%  { opacity: 0; }
  66%  { opacity: 0; }
  94%  { opacity: 0; }
  100%  { opacity: 1; }
}
.fade-in-2 {
  opacity: 0;
  animation-name: fadeIn2Opacity;
  position: absolute;
  top: 0;
  right: 0;
}
@keyframes fadeIn2Opacity {
  0%   { opacity: 0; }
  27%  { opacity: 0; }
  33%  { opacity: 1; }
  62%  { opacity: 1; }
  66%  { opacity: 0; }
  94%  { opacity: 0; }
  100%  { opacity: 0; }
}
.fade-in-3 {
  opacity: 0;
  animation-name: fadeIn3Opacity;
  position: absolute;
  top: 0;
  right: 0;
}
@keyframes fadeIn3Opacity {
  0%   { opacity: 0; }
  27%  { opacity: 0; }
  33%  { opacity: 0; }
  62%  { opacity: 0; }
  66%  { opacity: 1; }
  94%  { opacity: 1; }
  100%  { opacity: 0; }
}
</style>
<div class="fade fade-in-1">
<div style="text-align: left;"><b>0</b></div>
<img class="map-image" src="/images/cellular-automata-1.png"/>
</div>
<div class="fade fade-in-2">
<div style="text-align: center;"><b>1</b></div>
<img class="map-image" src="/images/cellular-automata-2.png"/>
</div>
<div class="fade fade-in-3">
<div style="text-align: right;"><b>2</b></div>
<img class="map-image" src="/images/cellular-automata-3.png"/>
</div>
</div>


Compilers are tricky. The slightest misstep will add extra instructions to the resulting assembly, causing artificial overhead in the final program. And sometimes, there's extra little bits of information you need to pass to the optimizer (or the CPU itself!) to trick it into the most optimal behavior. For two months, I tracked down these kinds of problems until I had something that looked reasonable.


To help me track down the problems, I kept comparing its assembly to the assembly generated by Vale's "unsafe" modes:

 * `unsafe_no_bounds` is similar to C; all memory-safety protections are turned off, and it only uses raw pointers for everything, rather than generational references.
 * `unsafe_with_bounds` then adds bounds checking for array accesses, similar to how Rust does it.


The resulting assembly looked nearly identical to Vale's `unsafe_with_bounds` mode. The only difference, of course, is that it put a pseudo-random generation number at the top of every allocation, though it never needed to read it for any generation checks. Luckily, that didn't seem to have any effect on the benchmarks.



So here are the conclusions:

```
Summary
  './build_unsafe_no_bounds/main' ran
    1.18 ± 0.01 times faster than './build_unsafe_with_bounds/main'
    1.18 ± 0.01 times faster than './build_safe_fastest/main'
```


In other words, Vale's safe mode had no extra overhead compared to just bounds checking!


These results are promising, though keep these caveats in mind too:

 * This is **not benchmarking against C and Rust.** Those compilers have years of unrelated optimizations that would just confound the benchmark, so I added `unsafe_no_bounds` and `unsafe_with_bounds` to isolate those variables and get a more accurate comparison of the memory safety approaches.
 * This was benchmarked on my Razer Blade 15" 2018 (512GB SSD) running Ubuntu 22.04, using [hyperfine](https://github.com/sharkdp/hyperfine) inside a [cset shield](https://manpages.ubuntu.com/manpages/trusty/man1/cset-shield.1.html).
 * When I made larger programs, I observed quite a bit of optimizer noise, where a minor change in one area would swing the entire benchmark results one way or another. [# In fact, when I switched the size of the generation numbers, it actually sped the program up to be _even faster_, `1.13 ± 0.01', which is a bit weird.]
 * In one program (a tiny roguelike game), I observed that the optimizer didn't perform some optimizations it should have, presumably because of the presence of the generation, even though the generation was never read. It's likely a bug in LLVM, but I can't say for sure.


That last one hints that we might want our own Vale-specific pre-optimizer, similar to Rust's [Cranelift](https://github.com/bytecodealliance/wasmtime/tree/main/cranelift), as LLVM was designed more with C in mind.


Still, even with these caveats, these results are quite promising!



# What does this mean?

This means that generational references and regions combine to form a memory safety approach that is very, very fast.


It means that we're seeing the beginning of an entirely new memory safety approach, that's faster than reference counting and tracing garbage collection, and easier than borrow checking.


# Where does Vale go from here?

The above benchmarks compared Vale's safe mode to Vale's unsafe modes, for a more accurate comparison of the memory safety approaches.


However, there are still a few things to do before Vale can really go toe-to-toe with languages like C++ and Rust.

 * Vale still needs to support inline data, instead of putting all structs on the heap. (Note that that wouldn't affect the above benchmarks, which didn't use any structs.)
 * I'll need to start a Vale-specific pre-optimizer, since LLVM has some problems reasoning about generations and immutability.
 * Regions are still just in the prototype phase. I'll need to smoothe out the rough edges, pay down a bit of tech debt, and merge this code in before I move onto anything else.


# Conclusion

It's been an epic and exciting journey to get to this point, from imagining to completing an entire new memory safety approach. And now, we _finally_ have some measurements to show that zero-check programs are possible, and they are as fast as we hoped.


I want to give a massive thanks to everyone that has helped with this endeavor, including our contributors and sponsors! I definitely would not have made it to this point without your support.


If you're impressed with our [track record](https://vale.dev/roadmap#recent-additions) and believe in the [direction we're heading](https://vale.dev/roadmap), please consider [sponsoring us on GitHub](https://github.com/sponsors/ValeLang)!

<center>
  <a href="https://github.com/sponsors/ValeLang" class="donate-button">
     <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-heart icon-sponsor mr-1 color-fg-sponsors">
        <path fill-rule="evenodd" d="M4.25 2.5c-1.336 0-2.75 1.164-2.75 3 0 2.15 1.58 4.144 3.365 5.682A20.565 20.565 0 008 13.393a20.561 20.561 0 003.135-2.211C12.92 9.644 14.5 7.65 14.5 5.5c0-1.836-1.414-3-2.75-3-1.373 0-2.609.986-3.029 2.456a.75.75 0 01-1.442 0C6.859 3.486 5.623 2.5 4.25 2.5zM8 14.25l-.345.666-.002-.001-.006-.003-.018-.01a7.643 7.643 0 01-.31-.17 22.075 22.075 0 01-3.434-2.414C2.045 10.731 0 8.35 0 5.5 0 2.836 2.086 1 4.25 1 5.797 1 7.153 1.802 8 3.02 8.847 1.802 10.203 1 11.75 1 13.914 1 16 2.836 16 5.5c0 2.85-2.045 5.231-3.885 6.818a22.08 22.08 0 01-3.744 2.584l-.018.01-.006.003h-.002L8 14.25zm0 0l.345.666a.752.752 0 01-.69 0L8 14.25z"></path>
     </svg>
     Sponsor us on GitHub!
  </a>
</center>

With your support, we can bring regions to programmers worldwide!


See you next time!

- Evan Ovadia


<slice new-color="afterword"/>

# Vale's Vision

Vale aims to bring a new way of programming into the world that offers *speed*, *safety*, and *ease of use.*


*The world needs something like this!* Currently, most programming language work is in:

 * High-overhead languages involving reference counting and tracing garbage collection.
 * Complex languages (Ada/Spark, Coq, Rust, Haskell, etc.) which impose higher complexity burden and mental overhead on the programmer.

These are useful, but there is a *vast field of possibilities* in between, waiting to be explored!


Our aim is to explore that space, discover what it has to offer, and make *speed and safety easier than ever before.*


In this quest, we've discovered and implemented a lot of new techniques:

 * [Generational Memory](/blog/generational-references), for a language to ensure an object still exists at the time of dereferencing.
 * [Higher RAII](/blog/raii-next-steps), a form of linear typing that enables destructors with parameters and returns.
 * [Fearless FFI](/blog/fearless-ffi), which allows us to call into C without risk of accidentally corrupting Vale objects.
 * [Perfect Replayability](/blog/perfect-replayability-prototyped), to record all inputs and replay execution, and completely solve heisenbugs and race bugs.


These techniques have also opened up some new emergent possibilities, which we hope to implement:

 * [Region Borrow Checking](/blog/zero-cost-borrowing-regions-overview), which adds mutable aliasing support to a Rust-like borrow checker.
 * [Hybrid-Generational Memory](/blog/hybrid-generational-memory), which ensures that nobody destroys an object too early, for better optimizations.
 * [Seamless concurrency](https://verdagon.dev/blog/seamless-fearless-structured-concurrency), the ability to launch multiple threads that can access any pre-existing data without data races, without the need for refactoring the code or the data.
 * Object pools and bump-allocators that are memory-safe and decoupled, so no refactoring needed.


We also gain a lot of inspiration from other languages, and are finding new ways to combine their techniques:

 * We can mix an `unsafe` block with Fearless FFI to make a much safer systems programming language!
 * We can mix Erlang's isolation benefits with functional reactive programming to make much more resilient programs!
 * We can mix region borrow checking with Pony's `iso` to support shared mutability.

...plus a lot more interesting ideas to explore!


The Vale programming language is a novel combination of ideas from the research world and original innovations. Our goal is to publish our techniques, even the ones that couldn't fit in Vale, so that the world as a whole can benefit from our work here, not just those who use Vale.


Our medium-term goals:

 * Finish the Region Borrow Checker, to show the world that shared mutability can work with borrow checking!
 * Prototype Hybrid-Generational Memory in Vale, to see how fast and easy we can make single ownership.
 * Publish the Language Simplicity Manifesto, a collection of principles to keep programming languages' learning curves down.
 * Publish the Memory Safety Grimoire, a collection of "memory safety building blocks" that languages can potentially use to make new memory models, just like Vale combined generational references and scope tethering.


We aim to publish articles biweekly on all of these topics, and create and inspire the next generation of fast, safe, and easy programming languages.


If you want to support our work, please consider [sponsoring us on GitHub](https://github.com/sponsors/ValeLang)!

With enough sponsorship, we can:

 * Work on this full-time.
 * Turn the Vale Language Project into a 501(c)(3) non-profit organization.
 * Make Vale into a production-ready language, and push it into the mainstream!

<center>
  <a href="https://github.com/sponsors/ValeLang" class="donate-button">
     <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-heart icon-sponsor mr-1 color-fg-sponsors">
        <path fill-rule="evenodd" d="M4.25 2.5c-1.336 0-2.75 1.164-2.75 3 0 2.15 1.58 4.144 3.365 5.682A20.565 20.565 0 008 13.393a20.561 20.561 0 003.135-2.211C12.92 9.644 14.5 7.65 14.5 5.5c0-1.836-1.414-3-2.75-3-1.373 0-2.609.986-3.029 2.456a.75.75 0 01-1.442 0C6.859 3.486 5.623 2.5 4.25 2.5zM8 14.25l-.345.666-.002-.001-.006-.003-.018-.01a7.643 7.643 0 01-.31-.17 22.075 22.075 0 01-3.434-2.414C2.045 10.731 0 8.35 0 5.5 0 2.836 2.086 1 4.25 1 5.797 1 7.153 1.802 8 3.02 8.847 1.802 10.203 1 11.75 1 13.914 1 16 2.836 16 5.5c0 2.85-2.045 5.231-3.885 6.818a22.08 22.08 0 01-3.744 2.584l-.018.01-.006.003h-.002L8 14.25zm0 0l.345.666a.752.752 0 01-.69 0L8 14.25z"></path>
     </svg>
     Sponsor us on GitHub!
  </a>
</center>


