---
title: Safety in Non-Memory-Safe Languages
subtitle: Part 1 of the Memory Safety Expedition
author: Evan Ovadia
date: Oct 8, 2022
realm: blog
path: blog/when-to-use-memory-safe-part-1
layout: annotated
namespace: c-blog m-annotated
sponsor: me
---


A few weeks ago, I was asked four questions all on the same day:

 * "When would we use C-like languages?"
 * "What language should I use for my game?"
 * "Why don't more people use Rust for web servers?"
 * "What are the benefits of borrow checking besides memory-safety and speed?"


The discussion had so many factors that I made it into a post, which very quickly exploded into a whole series. So here we are!


I love this topic because it's so nuanced: every language has its strengths and weaknesses, and there is no "one true language" that's best in every situation.


We'll mostly be comparing languages' approaches to *memory safety*, which is the prevention of common memory access bugs such as use-after-free.


Even if you're familiar with memory management, you'll likely learn some interesting things:

 * Less memory-safe languages are really well suited to a lot of situations!
 * Borrow checking has some pervasive hidden costs, and hidden architectural benefits!
 * Reference counting can be _way_ faster than we thought.
 * Development velocity is often more important than run-time performance!
 * Accessing released memory isn't always a bad thing.


# The Options


There are generally four approaches to memory safety:

 * *Garbage collection* (GC), like in Java, Go, Python, Javascript, etc. [# By "garbage collection" I'm specifically referring to tracing garbage collection.]
 * *Reference counting* (RC), like in Swift, Nim, Lobster, etc.
 * *Borrow checking*, like in Rust, Cone, Cyclone, etc.
 * *Manual memory management* (MMM), like in C, Ada, Zig, Odin, etc.


There's also a fifth approach, [generational references](https://verdagon.dev/blog/generational-references). We'll talk more about that elsewhere, this series is comparing the more traditional approaches.


Note that this is only Part 1. Subscribe to the [RSS feed](https://verdagon.dev/rss.xml), [twitter](https://twitter.com/vale_pl), or [subreddit](https://reddit.com/r/vale) to watch for the rest!


# The Tradeoffs

Memory safety approaches generally influence six aspects of a language:

 * *Extent*: How much memory safety does the approach offer?
 * *Development Velocity*: Are there obstacles to writing, changing, and maintaining code?
 * *Speed*: How fast does the code run?
 * *Memory*: How much memory does it consume?
 * *Simplicity*: Is your code simpler or more complex than with other approaches?
 * *Correctness*: Is the language more vulnerable to other kinds of bugs?


Different situations will prioritize these aspects differently, and will call for different languages.


Let's dive into the first one!


# Extent

To what extent does each approach help with memory safety?

This is a surprisingly nuanced topic. It's not a black-and-white thing, approaches can be anywhere on the memory safety spectrum.


 1. Manual memory management (MMM) has no built-in memory safety protection.
 1. Tool-assisted MMM uses things like [ASan](https://en.wikipedia.org/wiki/AddressSanitizer), [memory tagging](https://source.android.com/docs/security/test/memory-safety/arm-mte), and [CHERI](https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/) to detect a lot of problems in development and testing.
 1. Architected MMM [# This isn't an actual term in the industry, but I think it captures the spirit nicely.] uses more resilient patterns and architectures to drastically reduce the risk of memory unsafety even more.
 1. Statically-analyzed MMM uses frameworks like SPARK to be memory safe.
 1. Borrow checking is _almost_ safe, but comes with the `unsafe` escape hatch which can cause UB, even in the safe code around it.
 1. GC and RC generally offer complete memory safety. [# GC'd languages like Javascript and Lua are safe, and need no escape hatches.]


Let's talk about MMM first!


## MMM Languages' Memory Safety

Manual memory management by default has no memory safety protections.


If a programmer allocates every object with `malloc`, [# This includes objects that would have been inline in the stack or in other objects.] and gives it to `free` when it's last used, [# This might not the place that C++'s `unique_ptr` frees the object, because that might accidentally not be the last use of the object.] the program will be memory safe... in theory.


In practice, it's quite difficult to make a memory-safe program that way.


On top of that, if someone later updates the program, they'll likely violate some implicit assumptions that the original programmer was relying on, and then memory problems ensue.


To make matters a bit worse, programs made this way will be quite slow:

 * `malloc` and `free` are expensive: they can increase a program's run time by [as much as 25%](https://www.researchgate.net/profile/Benjamin-Zorn/publication/2626581_Improving_the_Cache_Locality_of_Memory_Allocation/links/56bbd28c08ae3f9793155449/Improving-the-Cache-Locality-of-Memory-Allocation.pdf?origin=publication_detail).
 * Since these allocations are on the heap, we no longer get *cache locality and cpu prefetching* benefits. We'll talk about this more in the "Run-time Speed" section.


As you can imagine, many successful MMM projects avoid `malloc` for these reasons.


There is, of course, a much better and safer way to use MMM languages.


But before that, let's be a little more specific: what _is_ memory safety, really?


## Memory safety isn't what you might think

Memory safety prevents common memory access bugs, including:

 * *Buffer overflows*, where we attempt to access the nth element of an array, when n is actually past the end of the array.
 * *Use-after-free*, which is when we dereference a pointer after we `free` it. 
 * *Use-after-return*, where we dereference a pointer to an object which lived in a function that has already returned.


These all have one thing in common: they risk accessing the wrong data, triggering [undefined behavior](https://en.wikipedia.org/wiki/Undefined_behavior) ("UB") which can result in cantankerous shenanigans like security vulnerabilities, segmentation faults, or random nearby data changing. [# Undefined behavior has also been known to cause computers to grow AIs and become sentient and hostile, probably.]


But sometimes, accessing the wrong data won't trigger undefined behavior, if the data there is still the type that we expect. [# Even this understanding isn't quite accurate. Memory unsafety theoretically can't occur if the memory is reused for a _different struct type with the same layout_, though in practice today's optimizers do interpret that as UB. If we want to go even further, we'd say that memory unsafety can only occur if we interpret a non-pointer as a pointer.]

So really, the goal of memory safety is to *access data that is the type we expect.*

This more accurate definition opens the door to a lot more useful, efficient, and safe approaches, as we'll see below.


## And sometimes, it doesn't completely solve the problem

Note that sometimes, we can trade a memory safety bug for another kind of bug.


For example, if we `free`'d a `ResponseHandler` but never unregistered it, the `NetworkManager` might still have a pointer to it when the response comes, triggering a use-after-free.

The outcome might be different in another paradigm:

 * In GC, we'd still act on the response, resulting in mysterious behavior on the client. We might also cause a [memory leak](https://www.baeldung.com/java-memory-leaks), despite having GC. [# This is why [Higher RAII](https://verdagon.dev/blog/higher-raii-7drl) is so nice, as it helps us remember to unregister handlers like this.]
 * In a borrow checked approach, we might look up the handler by index from a central array, but something else has reused that slot, so we give the response to the wrong handler, resulting in odd behavior. [# The proper solution to this is to use something like a SlotMap or HashMap that trades some performance for more intelligent reuse of space. In that case, we'd get an `Option`, and we can either panic, ignore it, or bubble it upward.]


These are technically logic bugs, better than undefined behavior, but our work is not done. We still need good engineering discipline, testing, and proper data handling practices no matter what approach we use.


## The safer way to use MMM languages

There are ways to drastically reduce the risk of memory safety problems, even when the language doesn't give you any protections itself. It has no official name, so I refer to it as *Architected MMM*.


There are some basic guidelines to follow:

 * Don't use `malloc`.
 * For long-lived allocations, use per-type arrays.
    * In a game, we might have an array for all `Ship`s, an array for all `Missile`s, and an array for all `Base`s.
 * For temporary allocations, one can also use an [arena allocator](https://www.rfleury.com/p/untangling-lifetimes-the-arena-allocator). [# One must still make sure that a pointer to an arena-allocated object does not outlive the arena allocator.]
 * For temporary allocations whose pointers don't escape, one can also use the stack. [# A pointer "escapes" if it lives past the end of the object's stack frame.]
 * All unions must be tagged [# A "tagged" union is a union that has an integer or an enum traveling alongside it, which keeps track of what the actual type is inside the union. One must always check the tag before accessing the data inside the union.] and treated as values. [# This means that we never take a pointer to a union, we instead copy it around. We might also only copy the data out of the union before accessing it.]
 * Always use bounds checking.


This is how a lot of embedded, safety-critical, and real-time software works, including many servers, databases, and games. [# For example, [TigerBeetleDB](https://github.com/tigerbeetledb/tigerbeetle/blob/main/docs/TIGER_STYLE.md#safety) has a similar set of rules.]


! Interestingly, the borrow checker also nudges us in this direction, though we often use things like Vec, SlotMap, or HashMap instead of arrays to trade a little bit of speed for better memory usage. [# Also check out [Hard Mode Rust](https://matklad.github.io//2022/10/06/hard-mode-rust.html) to see someone try to do this with completely pre-allocated data.]


This system mostly solves the aforementioned use-after-type-change bugs. To illustrate:

 * If we use a `Ship` after we've released it, we'll just dereference a different `Ship`, which isn't a memory safety problem.
 * If we use something in an arena allocator after we've released it, it will still be there because we never reuse an arena allocation for anything else.

These are still logic problems, but are no longer memory safety problems, and no longer risk undefined behavior.


Looking at modern MMM languages, this seems to be the direction they're emphasizing and heading toward:

 * Zig's [standard patterns](https://ziglearn.org/chapter-2/) include allocator parameters, exemplified in its standard library.
 * Odin has a [context system](http://odin-lang.org/docs/overview/#implicit-context-system) where you can use any allocator with any existing function, which means we don't need to specifically wire a function for it.

Both languages also have bounds checking by default, and all unions are tagged. [# The creator of Zig is also looking into adding [escape analysis](https://news.ycombinator.com/item?id=31853964), which is pretty exciting.]


The benefit of this approach is that it gets us much closer to memory safety without the particular drawbacks of GC, RC, or borrow checking.


## The safest way to use MMM languages

Practices like these have been formalized, and even integrated into static analysis tools like Ada's [SPARK](https://www.adacore.com/about-spark). One could even say the borrow checker is such a system, built into the language and enabled everywhere by default.


There are a lot of misconceptions about the safety of programs written in MMM languages. 

 * Some believe that civilization will collapse if we keep using MMM languages. This belief is, of course, undermined by the vast swath of safety-critical software written in them that hasn't yet caused a mass extinction event.
 * Some believe that we can guarantee the safety of `unsafe` code and MMM code if we just think about it hard enough. This also isn't true.


But with the right tooling, practices, and discipline, one can reduce the risk of memory safety bugs to an acceptable level for their situation.

This is also why we use languages like Rust, even though `unsafe` blocks can undermine and cause problems in the surrounding safe code.


If one needs _absolute_ safety, there are languages like Pony which have zero memory unsafety and less run-time errors than any other language, and tools like [Coq](https://coq.inria.fr/).


But in the real world we often don't need absolute guarantees, and we can use something with _sufficient_ memory safety, whether it uses constructs like `unsafe` blocks or tools like [ASan](https://en.wikipedia.org/wiki/AddressSanitizer) or [memory tagging](https://source.android.com/docs/security/test/memory-safety/arm-mte) or [CHERI](https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/). [#bias]


This is particularly nice because:

 * Without GC or RC, we can be as fast as possible.
 * We don't have to deal with the cognitive overhead or iteration slowdowns of SPARK and the borrow checker.
 * We can use fast approaches that the borrow checker and SPARK have trouble with, such as [intrusive data structures](https://lwn.net/Articles/907876/) and [graphs](https://news.ycombinator.com/item?id=24996001), plus useful patterns like [observers](https://www.reddit.com/r/rust/comments/pwqju6/is_there_an_underlying_reason_that_idiomatic_rust/), [back-references](https://users.rust-lang.org/t/back-reference-to-the-parent-struct/7413/2), [dependency references](https://en.wikipedia.org/wiki/Dependency_injection), [callbacks](https://news.ycombinator.com/item?id=12029238), [delegates](https://medium.com/@nimjea/delegation-pattern-in-swift-4-2-f6aca61f4bf5) and many forms of RAII [# RAII is about automatically affecting the world outside our object. To affect the outside world, the borrow checker often requires us to take a `&mut` parameter or return a value, but we can't change `drop`'s signature. To see this in action, try to make a handle that automatically removes something from a central collection. Under the hood we usually use `unsafe` mechanisms, including FFI.] and [higher RAII](https://verdagon.dev/blog/higher-raii-7drl).
 * We can reuse code and libraries written in non-memory-safe languages.
 * We can use interesting features unique to `unsafe` and non-memory-safe languages.


So how do we know if we don't need absolute memory safety?


<slice>
#bias: This also probably sounds odd coming from me, since Vale is completely memory safe. It would be very easy (and convenient) for me to claim that everyone should use my preferred level of memory safety.

However, a real software engineer puts their bias aside, and strives to know _when_ an approach's benefits are worth the costs.
</slice>


## When do we need memory safety?

Sometimes, we need memory safety to protect against very real risks:

 * When working with untrusted input (e.g. network-connected programs or drivers), it can help protect us against security breaches.
 * When working with multiple users' data, it can help protect their privacy from errant use-after-free reads.
 * When working on safety critical devices, it can protect our users from harm.


But for other situations, like many games and apps, the costs and burdens of certain memory safety approaches might not be worth it.


Let's talk more about these risks and when they occur.


### Memory Safety for Security-Sensitive Situations


Some programs handle untrusted input, such as web servers, certain drivers, etc. An attacker can carefully craft input that takes advantage of UB to gain access to sensitive data or take control of the system. Memory safety helps guard against that.


For example, if working on a server or a multiplayer game, you're handling a lot of untrusted input and you'll want memory safety to help with that.


Another example would be when writing a bluetooth driver. These radio waves could be coming from anywhere, and an attacker could craft an exactly right pattern to cause mischief and mayhem for the user.


In cases like these, we need to be careful and use more memory safe approaches.


However, not all programs handle untrusted input. [# "Untrusted input" can also be in the form of files. But if those files came with the program, such as assets for a game, then they are [trusted input and not as much of a problem](https://news.ycombinator.com/item?id=32879598).]


For example, the [Google Earth](https://earth.google.com/web/) app is written in a non-memory-safe language but it only takes input from the user and from a trusted first-party server, which reduces the security risk. [# Its sandboxing also helps, whether from webassembly, iOS, or Android.]


In cases like those, security doesn't need to be as much of a factor in language choice.


<slice />

### Memory Safety for Privacy-Sensitive Situations


Some programs reuse memory for multiple users. A use-after-free could mean that your web server could expose a user's private data to another user.


For example, let's say a server receives Bob's SSN from the database, but needs to wait for a second request before sending it all to Bob's phone. 

While Bob's SSN is hanging out in RAM, some buggy code handling Jim's request might do a use-after-free and read Bob's SSN, exposing it to Jim.

Memory safety helps by preventing use-after-frees like that.


Note that memory safety does not necessarily solve the problem. Borrow checking can [turn memory safety problems into privacy problems](https://news.ycombinator.com/item?id=32240161), and the same can be true of MMM approaches. [# Generational indices, memory tagging, and CHERI can help with this drawback.] No approach is perfect, but GC and RC seem to be the most resilient here.


However, not all programs handle data for multiple users.


For example, [Shattered Pixel Dungeon](https://shatteredpixel.com/) [# This game is amazing, it's open source, and I'm a [proud sponsor](https://www.patreon.com/ShatteredPixel/posts)!] is a mobile roguelike RPG game that just stores high scores and save files for a single user.


In cases like these, privacy doesn't need to be as much of a factor in language choice.


<slice />

### Memory Safety for Safety-Critical Situations


Some programs have safety critical code, where a bug can physically harm a user. The [Therac-25](https://en.wikipedia.org/wiki/Therac-25) had a bug that dosed six patients with too much radiation. One should definitely use a memory safe language for these cases.


However, most programmers aren't writing safety-critial code. My entire career has been on servers, apps, and games, and I generally don't connect them to anything explosive, incendiary, or toxic to humans.


<slice />

### Sometimes the worst case isn't that bad

Sometimes, memory unsafety bugs aren't as bad as all that.


For example:

 * In [Google Earth](https://earth.google.com/web), the occasional memory safety bug might crash the page and force a refresh, thus caused a 1-2 second inconvenience for the user.
 * In modern multiplayer games (plus older ones like Warcraft 3), when the program crashes, the players can restart and resume where they left off.
 * In a music player app, the user just restarts the app.


Bugs like these are generally as severe as logic problems, and we can use less burdensome techniques to detect and resolve them: tooling like [ASan](https://en.wikipedia.org/wiki/AddressSanitizer), [Valgrind](https://valgrind.org/), [release-safe mode](https://www.scattered-thoughts.net/writing/how-safe-is-zig/), [memory tagging](https://source.android.com/docs/security/test/memory-safety/arm-mte), [CHERI](https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/), etc. They aren't perfect, but they're very effective. We'll talk about these more below.


So what are these tools, and how might they help us easily improve our memory safety?


# Memory-safety tooling for MMM languages

## Sanitizers

The easiest way to detect most memory safety bugs is to use tools like [ASan](https://en.wikipedia.org/wiki/AddressSanitizer), [memory tagging](https://source.android.com/docs/security/test/memory-safety/arm-mte), [valgrind](https://valgrind.org/), etc. These are usually turned off in production, but we turn them on in:

 * Development.
 * Testing, especially integration tests.
 * [Canary](https://flagsmith.com/blog/canary-deployment/) servers.


The Google Earth folks used these pretty religiously. It might be surprising to hear, but the vast majority of memory safety bugs were caught in development and automated tests by Address Sanitizer. [# They didn't even use shared_ptr, they mostly used unique_ptr and raw pointers.]

In an average Google Earth quarter, they would get perhaps 60-80 bug reports, and memory unsafety was the root cause of *only 3-5% of them.* That's how effective Address Sanitizer can be.


## CHERI

On more modern hardware, you can also compile MMM languages with [CHERI](https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/).


CHERI works by bundling a 64-bit "capability" with every pointer, thus making every pointer effectively 128 bits. When we try to dereference the pointer, the CPU will check that the capability is correct, to help with memory safety.


It has [surprisingly little run-time overhead](https://lobste.rs/s/nw7hsd/how_memory_safe_is_zig_updated#c_tyzbaf)!


## Sandboxing with wasm2c

If you want to call into a library written in an MMM language, then you might benefit from using [wasm2c](https://hacks.mozilla.org/2021/12/webassembly-and-back-again-fine-grained-sandboxing-in-firefox-95/), for a modest performance cost (14% with all the platform-specific mechanisms enabled).


Note that there can still be memory corruption _inside_ the sandbox, which may or may not be an acceptable risk for the situation.


## Memory Tagging

[Memory tagging](https://source.android.com/docs/security/test/memory-safety/arm-mte) is a technique that takes advantage of how pointers and addresses work on modern operating systems.


A pointer is 64 bits, which means we theoretically have 2^64 bytes of address space. In reality, operating systems only use 48 to 56 bits of that, and don't use the other bits for addressing.


Memory tagging will generate a random 4-bit number for every chunk of memory. Whenever we create a pointer to that memory, it will put that 4-bit number *into the top unused bits of the pointer*. Later, when we try to dereference the pointer, it will check that those 4 bits still match the original 4 bits of the object. If they're different, that means the object has been freed already, and it will halt the program.


This is particularly good for debugging and testing. If this is enabled for your integration tests, then any invalid access bug has a 94% chance of being caught. [# And that chance increases to 99.6% if you run your integration tests twice, and so on!]


## MMM and Memory Safety

That pretty much covers the various approaches one can use with MMM, and to what extent they help with memory safety.


# A bloody _tome_

...said my friend when he saw how long this post was! It was already 45 pages and growing, so he had me cut it off here at 11. [# And I haven't even covered the more interesting tools like [ReleaseSafe mode](https://ziglang.org/learn/overview/), UBSan, or the various temporal memory safety approaches! But we've covered the basics.]


In the next posts, we talk about:

 * The extent of memory safety offered by borrow checking, GC, and RC.
 * Development velocity.
 * Run-time speed.
 * Memory usage.
 * Correctness.
 * Simplicity.

And at the very end, we'll have a comprehensive answer for when to use which approaches.


Thanks for reading! I hope this post has been intriguing and enlightening.


In the coming weeks I'll be continuing this series, so subscribe to the [RSS feed](https://verdagon.dev/rss.xml), [twitter](https://twitter.com/vale_pl), or the [subreddit](https://reddit.com/r/vale), and come hang out in the [discord server](https://discord.gg/SNB8yGH)!


If you found this interesting or entertaining, please consider sponsoring me:

<center>
  <a href="https://github.com/sponsors/ValeLang" class="donate-button">
     <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-heart icon-sponsor mr-1 color-fg-sponsors">
        <path fill-rule="evenodd" d="M4.25 2.5c-1.336 0-2.75 1.164-2.75 3 0 2.15 1.58 4.144 3.365 5.682A20.565 20.565 0 008 13.393a20.561 20.561 0 003.135-2.211C12.92 9.644 14.5 7.65 14.5 5.5c0-1.836-1.414-3-2.75-3-1.373 0-2.609.986-3.029 2.456a.75.75 0 01-1.442 0C6.859 3.486 5.623 2.5 4.25 2.5zM8 14.25l-.345.666-.002-.001-.006-.003-.018-.01a7.643 7.643 0 01-.31-.17 22.075 22.075 0 01-3.434-2.414C2.045 10.731 0 8.35 0 5.5 0 2.836 2.086 1 4.25 1 5.797 1 7.153 1.802 8 3.02 8.847 1.802 10.203 1 11.75 1 13.914 1 16 2.836 16 5.5c0 2.85-2.045 5.231-3.885 6.818a22.08 22.08 0 01-3.744 2.584l-.018.01-.006.003h-.002L8 14.25zm0 0l.345.666a.752.752 0 01-.69 0L8 14.25z"></path>
     </svg>
     Sponsor me on GitHub!
  </a>
</center>

With your help, I can write this kind of nonsense more often!

