---
title: Language Complexity: What it is, When it's Good, and How to Do it Right
author: Evan Ovadia
date: Feb 15, 2022
realm: blog
path: blog/language-simplicity
layout: annotated
namespace: c-blog m-annotated
---



Tomorrow's languages need to be simpler than the ones we have today. That might sound obvious.


It's actually harder than you'd think because *the way we think about complexity in today's languages is mostly wrong.*


Most people think that: [#riddles]

 * Python is as simple as a language can be.
 * C++ keeps getting more and more complex as time goes on.
 * Rust is complex because it has to be.


All of these statements are mostly incorrect. By the end of this article, you'll see why.


This article aims to answer the fundamental questions of complexity: what even _is_ complexity, when is it good or bad, and what makes a language "too complex"? 


<slice>
#riddles: Notes to self:

"Python is simple as a language can be": wrong because it doesnt surface the inherent complexity of types, and so doesnt reduce that complexity for the user

"C++ keeps getting more and more complex as time goes on": wrong because foreach loops actually reduce complexity even though the language gets more complex.

"Rust is complex because it has to be": wrong because it's situational complexity. it's way more complex in web servers.
</slice>


# Complexity Is Relative

In 2014, our team centralized our app's state into a central StateManager V2 which worked similarly to today's Redux.

"The old solution is too complex! The new solution is simple." we said. We replaced it, bugs decreased, and life was better.


In 2017, new members joined the team, and proposed a new StateManager V3.

"The old solution is too complex! This proposal is simple." they said. So they replaced it, and bugs decreased even further, and life was even better.


Of course, V2 was not "too complex". It only became too complex once we had a simpler alternative.


The same is true with languages. *When we say something is simple or too complex, it is relative.*



# Complexity Is Situational

Some language's complexities seem to arise in certain situations and not others. Functional programming is stellar when transforming data, but in cases with a lot of state, we need to bring in more complex concepts such as monads. We might call this **situational complexity.**


Everything below here should be taken in context. If it's a general purpose language, then measure it against general purposes. If it's a domain specific language, measure it against the specific domain.





# Inherent Complexity

Python is often regarded as a simple language, because it doesn't have static typing.


However, even though the compiler doesn't track types, we often still need do that in our heads. The types exist conceptually, even if the compiler doesn't know about them at compile-time. We humans still need to track types manually. This seems to be **inherent complexity**, complexity that is there even if the language does not track it.


need example

mention it's situational


# Artificial Complexity


need another example

mention its situational again



# Complexity is irrelevant, minimize burden

The only thing that matters is how much the user has to think about.

Typescript adds a complex feature, static typing, to help manage the inherent complexity of types.

It's a more complex situation all around!

However, it makes programming easier for the user, and that's what's important.


*We shouldn't minimize complexity, we should minimize burden.*


Other examples:

 * Vale's regions, Pony's `iso`, and Rust's borrow checker were all added to help protect the user from the inherent complexity in multithreading. We need to think less because of it.
 * In some domains, Rust's borrow checker adds complexity, but reduces the programmer's burden of optimizing their code.



The challenge is that they often come hand in hand. For example:

 * some examples of complexity that pisses me off


So what kinds of complexity help burden, and what kinds of complexity reduce burden? Read on!



# Opt-in Complexity

In C#, one can write an entire program without knowing about the `struct` keyword. But if one wants more performance, they can opt-into more complexity. Perhaps this **opt-in complexity** is a good thing?


Other examples:

 * 


# Ignorable Complexity


In Vale's design, one can write an entire program with just the base building blocks: owning references and non-owning references. If one wants to go the extra mile for more performance, they can use inline objects, regions, allocators, and override gen-checks with an operator. However, these don't change the semantics of the program, just the performance characteristics. A new user can successfully ignore these details and know what the program is doing. This **ignorable complexity** seems pretty good. (Note: These features aren't all done, but useful for discussion.)


Counterexample: C++?


# Remediable Complexity


In Java, a foreach loop uses an iterator under the hood.


# Emergent Complexity


In Rust, the borrow checker is based around one central principle, aliasability-xor-mutability (we can have one mutable reference xor many shared references to an object). This simple rule creates a lot of complexity for real-world programming, and makes us use patterns we might not naturally have opted for. Is the borrow checker simple or complex? Or perhaps both: fundamentally simple, but with high **emergent complexity**.


# Up-Front Complexity

Also in Rust, the borrow checker's complexity hits the programmer all at once when learning the language. This is **up-front complexity**, compared to the more gradual complexity of e.g. C#.


# Compounding Complexity

Also in Rust, the borrow checker can clash with other aspects of the language, such as async/await. Two simple features can cause **compounding complexity.**


The opposite of this is "composable" complexity.


# Composable Complexity

Most languages have complex sub-languages to express generics (e.g. `<T extends IShip>` etc). However, Zig was able to combine one feature (comptime) with another feature (static typing) to be able to add generics with no complex sub-language. Their features **aligned to reduce complexity** compared to other languages, assuming they would have added generics anyway (which is uncertain but beside the point).


# A Proper Abstraction

Proper abstraction will surface inherent complexity, 


# How to handle complexity


To make a language great, one should help with the situation's inherent complexity, and not cause artificial complexity. If it's complexity inherent to programming itself, make a general purpose language. If it's inherent to a specific domain, make a domain-specific language.

Now, let's add some complexity to help with inherent complexity.

Firstly, check if it's up-front complexity. Make it ignorable complexity if possible, or opt-in complexity.

Now, ensure it fits with the rest of the language. Avoid compounding complexity. Prefer composable complexity, try to find a way to make it fit better with the rest of the language.



# Conclusion

Of course, these are lofty ideals, but in real language design we need to add complexity to offer the power our users want. Language design is an art in balancing complexities and the powers they enable in the best way possible.

I'd love to hear your opinions! What do you think complexity is? What are some great examples of languages handling complexity well?





# NOTES

Incorporate feedback and comments from https://www.reddit.com/r/ProgrammingLanguages/comments/vtph4p/what_is_language_complexity_when_is_it_good_and/



Adding complexity help manage inherent complexity to reduce burden.
This would be better if we didnt use "complexity" for both the added complexity and the stuff already inherent.



If you don't consider undefined behavior, C is a big step forward. By adding more features (becoming more complex) it makes software simpler. By taking away irrelevant redundant details, we can focus on what makes one piece of code actually different from another.

By adding some language complexity, we've reduced the user's complexity.

C is a good abstraction.

And fundamentally, that's what a programming language is all about: offering the proper abstractions.

Language design is about balancing abstractions and restrictions to give the user the most power with the least complexity.







## Abstract

This article spells out a very desirable aspect of a programming language: simplicity.

It is easy to say "a language should be simple". In practice, such a simplistic notion rarely helps, because simplicity is fundamentally at odds with other goals (speed, memory safety, etc).

This article describes how to identify and strive for simplicity.

Throughout the article, we'll use Java, C++, and Vale as examples. In follow-up articles, we'll measure Rust, Haskell, and Python as well.



## Incidental Complexity

We should try to minimize incidental complexity.



## Inherent Complexity

If we get rid of all of the incidental complexity, is our thing simple?

Not yet. We still have inherent complexity, complexity that must be present.

However, we can reduce the impact of this inherent complexity, such as via abstraction.


## Learning Curve Complexity

Some complexity is easier to keep in our heads than others. Some is easy to learn, for example types. Some keeps haunting you, such as AxM or immutability. Single ownership is somewhere inbetween.


## Simplicity Measures Mental Resource Usage

Simplicity is how well something fits into the programmer's head.

Here's a view with three components that interact. It tangles them together. All of this logic *must* be present.

But if we separate them into sub-components, we suddenly have less complexity, because for any given task we can safely forget a lot of details.

We no longer have to remember more details and constraints.



GC is the king of simplicity.

Adding constraints, like immutability, or AxM, or UB, increases complexity.



# Why We Want Simplicity

simplicity should be one of the top secondary priorities


1. because youll be hiring newgrads and teaching them, and that will take a lot of time. if the language is difficult, this could cause churn, further shortening the usefulness. [# this is the main factor for why I recommend people make their programs in java, believe it or not.] this was a major problem in google, we couldnt hire c++ developers, so we hired people who we had to teach.
2. because youre trying to get new users. if the complexity turns people off, they likely wont come back. its difficult to recover from a failed launch, because people dont readily give a product a second chance.
3. because not everyone looks at programming as a fascinating puzzle to solve. most programmers are trying to get something done, and want the language to get out of the way so they can do it. two kinds of complexity: initial and inherent. example: c++'s enable_shared_from_this is inherent because you keep running into it.


# How We Lose It

simplicity is something we accidentally give up as we pursue other priorities, such as speed or safety.
a language has a reasonably finite complexity budget.


how do you know if a language is complex? don't ask those who are good at it. theyre very quick to profess how easy it was for them, because theyre very invested in the language. ask those who have explored it and moved on.



# Common Sources of Complexity

## Static Typing

simplicity can be moved elsewhere in time. with dynamic typing, we still have to think about types, just later. except we can let ourselves not think about it for a bit, and lean on the compiler to get us back on track. so we dont have to think about it *as much*.


# Non-Tricks to Reduce Complexity

talk about tactical simplicity vs strategic simplicity. we can sacrifice simplicity at one level for simplicity at another.


# Tricks to Reduce Complexity

## Composability

When we can combine two features to achieve the effects of another, thats more simple.

one must look at the combination power of the basics; the basics are the minimum set of features one needs, to combine to write their program.


## Adding Simplifying Features

adding features can make real life simpler. see c++. an example of opt-in complexity?


## Optimization Hints

Like C#'s struct


some tools:
- hints. if someone knows they can ignore something completely, then the language remains simple.
- fix suggestions; if the compiler can show you how to fix something and why, and its guaranteed to solve that problem (unlike rust lol) then the feature has little negative impact.
- have opt-in advanced features. example: c# structs, vale regions, you should be able to make any program knowing less than 5% of the language. if the language forces newbies into another advanced concept every day, its not as good.
  - vale has only one: single ownership.
- familiarity. innovation is good, but wherever possible, stick to familiar syntax and paradigms and build off of them. where you do diverge, make it easy to realize, or optional.










make it as simple as possible, and no simpler
"If I had more time, I would have written a shorter letter". Simplicity takes effort. It takes time.

a lot of language design is deciding how much complexity is in the language and how much is in user-space.



In vale, I had to keep my eyes open for opportunities to simplify.

i'll use vale as an example because it's famously difficult to have speed and safety without incurring a massive complexity cost.

